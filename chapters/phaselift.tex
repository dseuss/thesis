 % -*- root: ../thesis.tex -*-
\chapter{Characterizing linear-optical networks via PhaseLift}%
\label{chap:phaselift}


\todo{The physics part needs work}
\todo{Norm of vector = intensity}
\todo{Why RECR better?}

Linear-optical networks composed of beamsplitting and phaseshifting operations are fundamental to the quantum and classical processing of information with light.
Passive and reconfigurable linear optical circuits have been proposed and demonstrated for many applications including telecommunications~\cite{Miller_2015_Sorting}, machine learning~\cite{Shen_2017_Deep} and quantum computation~\cite{Carolan_2015_Universal} and simulation~\cite{Harris_2017_Quantum}.
With the continuing development of large-scale integrated photonic platforms~\cite{Silverstone_2016_Silicon,Seok_2016_LargeScale}, practical and reliable techniques for characterizing and validating the operation of these devices are crucial.
In this work, we present new protocols for characterizing linear optical devices with low experimental resources by exploiting a connection to the phase retrieval problem \cite{Walther_1963_Question}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Devices Characterization}%
\label{sec:pl.optics}

\todo{Fix}

Theoretically, a linear optical device is fully characterized by its \emph{transfer matrix} ${M}$.
We consider as input to the device classical light described by a multimode coherent state $\ket{{\alpha}} = \ket{\alpha_1, \ldots, \alpha_n}$.
Due to the linearity of the device, this input is mapped to a coherent state $\ket{{\beta}}$ in the output via
\[
  \beta_j = \sum_k M_{j,k} \,\alpha_k.
  \label{eq:pl.coherent_transfer_matrix}
\]
Determining ${M}$ experimentally is the crucial step to validate and verify an existing linear optical circuit.
The standard measurable quantities in an optical experiment are the \emph{intensities} of the output modes
\[
  I_j({\alpha})
  = \left| \beta_j \right|^2 + \epsilon_j
  = \left| \sum_k M_{j,k} \, \alpha_k \right|^2 + \epsilon_j
  \label{eq:pl.intensities}
\]
for certain coherent inputs $\ket{{\alpha}}$.
Here, $\epsilon_j$ describes noise due to statistical fluctuations or systematic errors.
Although the output coherent states~\eqref{eq:pl.coherent_transfer_matrix} are linear in ${M}$, the resulting intensity measurements~\eqref{eq:pl.intensities} are quadratic in ${M}$ and oblivious to the phases of $\beta$.
Therefore, the problem of reconstructing ${M}$ from such measurements is ill-posed and requires deliberate utilization of inference between the modes to recover the phases of $M$.

Well-known techniques for fully characterizing photonic circuits include quantum process tomography with non-classical~\cite{Brien_2004_Quantum} or coherent~\cite{Keshari_2011_Quantum} states, though these approaches scale exponentially with the number of modes.
Simpler protocols tailored to linear optics have been proposed that use either single and two-photon probe states~\cite{Laing_2012_SuperStable,Dhand_2016_Accurate,Spagnolo_2017_Learning} or multimode coherent states~\cite{Keshari_2013_Direct,Tillmann_2016_On}.
The most similar scheme to the one presented here is~\cite{Keshari_2013_Direct}, where coherent light is input into single modes and split over pairs of modes with the intensity at each output measured.
While their recovery method is strikingly simple and relies only on $2n-1$ input configurations, for each configuration it requires varying over a phase shift between the two modes until maximal constructive interference is observed.
Furthermore, by construction, it propagates information about ${M}$'s first row to the remaining ones.
The first requirement results in an interactive experiment, where the inputs need to be adjusted gradually throughout an individual measurement.
\todo{Not quite correct.}
Moreover, the second feature of the recovery protocol makes it a priori susceptible towards noise as any error in the determination of the first row propagates to the remaining rows.

Although, as we have described, the protocol can be performed using coherent states and photodiodes, for this experimental demonstration we instead use heralded single photons and single photon detectors.
This is because the properties of the components and, therefore $ M$ are generally mode-dependent, that is dependent on the wavelength, polarization, etc.\ of the light.
Since it is the goal to characterize the device for quantum experiments, the most accurate characterization for this purpose is achieved using the same mode of light used in the future quantum experiments. .
When a single photon Fock state is input in the bottom waveguide, the prepared state prior to $ M$ is
\[
  \ket{\psi({\alpha})} = \sum_k \alpha_k a_k^{\dag} \ket{\mathfrak{0}}
\]
where $\ket{\mathfrak{0}}$ denotes the vacuum state.
The transfer matrix $M$ performs the mapping $a_k^{\dag} \rightarrow \sum_j M_{j,k}a_j^{\dag}$.
The probability of measuring the photon at detector $j$ is then given by
\[
  \Prob(j|{\alpha}) = \left| \sum_k M_{j,k} \alpha_k \right|^2.
  \label{eq:pl.experiment.probabilities}
\]
Hence, finite-sample frequency estimates of the probabilities~\eqref{eq:pl.experiment.probabilities} are equivalent to the noisy intensity measurements~\eqref{eq:pl.intensities}.
In the experiment, a spontaneous parametric down-conversion process is used to produce a heralded single photon via the detection of its correlated pair photon in the idler mode.

The silica-on-silicon device performs a linear-optical circuit comprising 30 directional couplers and 30 tunable thermo-optic phase-shifters on six optical waveguides \cite{Carolan_2015_Universal}.
As shown in \cref{fig:experimental.schematic}, inputting coherent light into the bottom waveguide of the device, an initial cascade of five Mach-Zehnder interferometers (MZIs) and accompanying phase-shifters can be used to prepare any five-mode input vector $\ket{{\alpha}}$.
The remaining triangular array of components is then sufficient to implement any five mode unitary transfer matrix $M$~\cite{Reck_1994_Experimental}.
Reconfiguring the target $M$ then enables us to experimentally test the protocol across a number of configurations including Identity, Swap, and Fourier matrices as well as Haar random unitaries.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tbp]
  \centering
  \includegraphics[width=0.95\columnwidth]{fig/phaselift_schematic}%
  \caption{%
    Schematic of phaselift characterisation protocol and experiment.
     a) Protocol summary (see \cref{prot:pl.detailed_reconstruction}).
     A calibrated and trusted network is used to prepare multimode coherent states $\singleket{\boldsymbol{\alpha}}$, sampled from the uniform or RECR ensembles.
     This state is then input to an unknown linear optical device described by the transfer matrix $ M$, and the intensities at each output port are measured.
     b) Experimental schematic.
     Heralded single photons are input into the bottom waveguide of a six-mode integrated photonic device.
     A cascade of Mach-Zehnder interferometers is used to prepare single-photon states $\singleket{\psi( \alpha)}$ over the bottom five modes of the device.
     The remainder of the device is used to implement arbitrary 2, 3 and 5 dimensional unitary transformations which are to be characterized.
     Each output port is coupled to a single photon detector.
   }
  \label{fig:experimental.schematic}
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Phase Retrieval}%
\label{sec:pl.phase_retrieval}

The crucial observation of this work is that measurements~\eqref{eq:pl.intensities} closely resemble the model of the \textit{phase retrieval problem}, i.e.\ the problem of recovering a complex vector ${x} \in \Complex^n$ from $m$ intensity measurements of the form
\[
  y\ind{l}= \Abs{\braket{\alpha\ind{l}, x}} + \epsilon\ind{l}
  \quad l=1,\ldots,m.
  \label{eq:pl.phase_retrieval_measurements}
\]
Here, $\alpha^{(l)} \in \Complex^n$ denote measurement vectors and $\epsilon^{(l)}$ the additive measurement errors.
The major difficulty in recovering $x$ from these intensity measurements is the loss of phase information.
In order to infer the phase information, we need to exploit interference effects by carefully selecting different measurement vectors.
However, $x$ can only be recovered up to a global phase since $x$ and $\ee^{\ii\phi} x$ are indistinguishable from the measurements~\eqref{eq:pl.phase_retrieval_measurements} for any argument $\phi$.

One practical solution to the phase retrieval problem is based on its connection to the field of low-rank matrix recovery.
The quadratic measurements of $x$ in \cref{eq:pl.phase_retrieval_measurements} can be rewritten as
\[
  \left| \langle {x}, \alpha^{(l)} \rangle \right|^2
  = \tr \left( (\ket{\alpha^{(l)}}\bra{\alpha^{(l)}}) (\ket{{x}}\bra{{x}}) \right).
\]
This \quotes{lifts} the phase retrieval problem to the problem of recovering the positive semi-definite (psd) rank-1 matrix $\ketbra{x}$ from linear measurements.
The latter -- and its generalization to arbitrary low-rank matrices -- have been studied extensively in the field of \emph{low-rank matrix recovery}, see e.g.~\cite{Ahmed_2014_Blind,Candes_2009_Exact,Candes_2011_Tight,Recht_2010_Guaranteed,Gross_2011_Recovering,Chen_2015_IncoherenceOptimal} for a highly incomplete list of references.

The fundamental idea is to find the matrix $Z$ with the smallest rank that is compatible with the observations.
As an example, consider the idealized noiseless case of \cref{eq:pl.phase_retrieval_measurements}, i.e.\ $\epsilon\ind{l} = 0$.
Then, we can reconstruct $\ketbra{x}$ using the following rank-minimization problem
\[
  \begin{split}
    \underset{{Z}}{\textrm{minimize}} &\quad \rank Z \\
    \textrm{subject to} &\quad  \tr\left( \ketbra{\alpha\ind{l}} \, Z \right) = y_l \quad (l=1,\ldots,m)
  \end{split}
  \label{eq:pl.rank_minimization}
\]
provided $m$ is sufficiently large to single out $\ketbra{x}$.
However, rank minimization is $\NP$-hard in general~\cite{Boyd_2004_Convex}, and therefore, \cref{eq:pl.rank_minimization} cannot be solved efficiently.
Nevertheless, there are algorithms for recovering $\ketbra{x}$ that are computationally efficient with only a slight overhead in the number of measurements required.
Here, we consider the following convex algorithm termed \emph{PhaseLift}~\cite{Candes_2013_Phaselift}
\[
  \label{eq:pl.PhaseLift}
  \begin{split}
    \underset{{Z}}{\textrm{minimize}} & \quad \sum_{l=1}^m \left| \tr \left( \ket{\alpha^{(l)}} \bra{\alpha^{(l)}} \, {Z} \right) - y^{(l)} \right| \\
    \textrm{subject to} &\quad  {Z} \geq 0. \nonumber
  \end{split}
\]
From the minimizer $Z^\sharp$ of \cref{eq:pl.PhaseLift}, we obtain the recovered signal vector ${ x}^\sharp$ as follows:
Consider the eigenvalue decomposition of $Z^\sharp$
\[
  Z^\sharp = \sum_i \lambda_i \ketbra{z_i}
\]
with $\ltwonorm{z_i} = 1$ and $\lambda_1 \ge \lambda_2 \ge \ldots \lambda_n$.
Then, we set
\[
  x^\sharp = \sqrt{\lambda_1} y_1.
  \label{eq:pl.vector_from_matrix}
\]

Several analytic proofs of convergence have been established for phase retrieval via PhaseLift.
With few notable exceptions~\cite{Kech_2016_Explicit}, these are probabilistic in nature and assume that each measurement vector is chosen from an appropriate distribution.
Paradigmatic examples are the Gaussian and the uniform (spherical) measurement ensemble~\cite{Candes_2013_Phaselift}.
In case of the Gaussian ensemble, the components $\alpha\ind{l}_i$ of the measurement vectors are i.i.d.\ complex Gaussian random variable.
In the uniform scheme, the $\alpha^{(l)}$ are chosen uniformly from the complex unit sphere.
The two are highly related, as the latter arises by normalizing all Gaussian vectors to a fixed value.
However, these two measurement examples are often unsuitable for practical applications, which led to a large body of work proving similar recovery guarantees  for measurement ensembles that feature less randomness~\cite{Gross_2014_Partial,Kueng_2014_Low,Kueng_2014_Low,Kueng_2016_Low} or additional structure tailored to specific applications~\cite{Candes_2013_Phaselift,Gross_2017_Improved,Voroninski_2013_Quantum,Kueng_2015_Low}.

The main theoretical contribution of this chapter is such a recovery guarantee for a measurement ensemble motivated by the experimental architecture of linear optical devices:
The \emph{randomly erased complex Rademacher} (RECR) ensemble requires only four phase shifter settings per mode, and hence, is easier to implement experimentally than e.g.\ the uniform ensemble, which necessitates the ability to prepare any phase shift.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Theory for Characterization via Phase Lift}%
\label{sec:pl.theory}

\subsection{The RECR ensemble}%
\label{sub:pl.recr}

The uniform ensemble introduced in \cref{sub:intro.phase_retrieval} is well-suited for a theoretical analysis.
However, this sampling scheme places high demands on the experimental implementation since it necessitates the ability to prepare any coherent input state $\ket{\alpha}$ with $\alpha$ from the complex unit sphere.
Therefore, we propose an alternative measurement ensemble that lends itself better to implementations in linear optics:
For $p \in [0,1]$, we define a \emph{randomly erased complex Rademacher} (RECR) random variable $a$ to be distributed according to
\[
  a \sim
  \begin{cases}
    +1 & \textrm{with prob. } p/4 \\
    +\ii & \textrm{with prob. } p/4 \\
    0 & \textrm{with prob. } 1-p \\
    -\ii & \textrm{with prob. } p/4 \\
    -1 & \textrm{with prob. } p/4
  \end{cases}
  \label{eq:pl.recr_definition}
\]
For the RECR measurement model, we sample the components $\alpha\ind{l}_k$ of the input states $\ket{\alpha\ind{l}}$ according to \cref{eq:pl.recr_definition}.
In practice, we use its normalized version with constant total intensity $\ltwonorm{\alpha} = 1$.
Since there are only four different values for the phases of the components~\eqref{eq:pl.recr_definition}, the RECR scheme is easier to implement experimentally as we discuss in \cref{sub:pl.characterization}.\\



The rest of this section is devoted to proving recovery guarantees for the RECR ensemble for phase retrieval via PhaseLift~\eqref{eq:pl.PhaseLift}.
In order to be more self-contained, we also include a similar proof for the uniform scheme, which later serves as a reference.
More generally, we consider ensembles of measurement vectors $\alpha$ that satisfy the following conditions for constants $C_\mathrm{I}$, $C_\mathrm{SI}$, and $C_\mathrm{SG}$:

\begin{itemize}
  \item \emph{Isotropy on $\mathbb{C}^n$:}
  \[
    \mathbb{E} \left[ | \langle \alpha,  z \rangle |^2 \right] = C_\mathrm{I} \|  z \|_{\ell_2}^2 \quad \forall  z \in \mathbb{C}^n.
    \label{eq:pl.tight_frame}
  \]

  \item \emph{Sub-Isotropy on $\Hermitian^n$}, the Hermitian $n \times n$ matrices:
  \begin{align}
    \mathbb{E} \left[ \langle \alpha,  Z \alpha \rangle^2 \right] \geq C_\mathrm{SI} \|  Z \|_2^2 \quad \forall  Z \in \Hermitian^n \label{eq:pl.sub_isotropy}
  \end{align}

  \item \emph{Sub-Gaussian tail behavior:} For every normalized $ z \in \mathbb{C}^n$ ($\|  z \|_{\ell_2}=1$), $| \langle \alpha,  z \rangle|$ is sub-Gaussian in the sense that its moments obey
  \[
    \mathbb{E} \left[ | \langle \alpha,  z \rangle|^{2N} \right] \leq C_\mathrm{SG} N! \quad N \in \mathbb{N}.
  \label{eq:pl.subexponential}
  \]
\end{itemize}

\begin{proposition}%
  \label{prop:gauss+recr_requirements}
  The following measurement ensembles fulfill the three properties above:
  \begin{enumerate}
    \item \emph{Gaussian sampling scheme:} $\alpha \in \mathbb{C}^n$ chosen from the standard complex normal distribution $\mathcal{N}(0,\tfrac{1}{2}\mathbb{I})+ i \mathcal{N}(0,\tfrac{1}{2}\mathbb{I})$.
    In this case
    \[
      C_\mathrm{I} = C_\mathrm{SI} = C_\mathrm{SG} = 1.
    \]

    \item \emph{Uniform sampling scheme:} $\alpha \in \mathbb{C}^n$ chosen uniformly from the complex unit sphere with radius $\sqrt{n}$.
    In this case
    \[
      C_\mathrm{I} = 1, \; C_\mathrm{SI} = \frac{n}{n+1}, \; C_\mathrm{SG} = \prod_{k=1}^{N-1} \frac{n}{n+k} \leq 1.
    \]

    \item \emph{(unnormalized) Randomly Erased Complex Rademacher (RECR) sampling scheme:} the components of $\alpha \in \mathbb{C}^n$ are chosen independently from the distribution~\eqref{eq:pl.recr_definition}.
    The constants depend only on the erasure probability $1-p \in [0,1]$:
    \[
      C_\mathrm{I} = p,\; C_\mathrm{SI} = p \min \left\{p,1-p \right\}, \; C_\mathrm{SG} = \mathrm{e}^{\frac{3}{2}}.
    \]
  \end{enumerate}
\end{proposition}
Unfortunately, the proof techniques developed here do not apply to the normalized RECR scheme used in the experimental work.
We comment on potential extension to this case in \cref{sub:pl.normalized_recr}.

The following statement is a substantial generalization of existing results regarding phase retrieval from Gaussian and uniform measurements~\cite{Candes_2012_Solving,Demanet_2014_Stable}:
\begin{theorem}[Theorem 1.3 in~\cite{Candes_2012_Solving}]%
  \label{thm:pl.phaselift_noisy}
  Suppose that $m = Cn$ vectors $\alpha\ind{1},\ldots,\alpha\ind{m} \in \mathbb{C}^n$ have been chosen independently at random from an ensemble that obeys the three properties~\eqref{eq:pl.tight_frame}, \eqref{eq:pl.sub_isotropy} and~\eqref{eq:pl.subexponential}.
  Then, the optimizer $X^\sharp$ of the convex program~\eqref{eq:pl.PhaseLift} satisfies
  \[
    \fnorm{{X}^\sharp - \ketbra{x}} \leq \frac{C'  \norm{\epsilon}_{\ell_1}}{m}.
    \label{eq:pl.noisy_recovery_bound}
  \]
  with probability at least $1 - 3\mathrm{e}^{-\gamma m}$,
  Here, $\fnorm{\cdot}$ denotes the Hilbert-Schmitt norm $\fnorm{Z}^2 = \tr \left( {Z} {Z}^\dagger \right)$, while $C,C'$ and $\gamma$ represent constants of sufficient size.
  Furthermore, $\norm{\epsilon}_{\ell_1}$ is a bound on the total noise of all measurements~\eqref{eq:pl.phase_retrieval_measurements}
  \[
    \norm{\epsilon}_{\ell_1} = \sum_{l=1}^m \abs{\epsilon\ind{l}}.
  \]
\end{theorem}

The constants $C$, $C'$, and $\gamma$ implicitly depend on ensemble constants $C_\mathrm{I}$, $C_\mathrm{SI}$, and $C_\mathrm{SG}$ and can in principle be extracted from the proof.
Note that although we are recovering $\ketbra{x}$, which is embedded in the $n^2$ dimensional space of all $n \times n$ matrices, the demand on the number of measurements $m$ in \cref{thm:pl.phaselift_noisy} scales linearly in the original problem's dimension $n$.
This is optimal up to the constant multiplicative factor $C$.
Analytical bounds on this constant $C$ are usually too pessimistic to be practical and it is widely believed that
\(
  m = 4n - 4
\)
such measurements are actually sufficient, that is $C = 4 + o(n)$~\cite{Heinosaari_2013_Quantum}.

We postpone the proof of this result to \cref{sec:pl.main_proof} in order to derive an error bound for the signal vector from \cref{thm:pl.phaselift_noisy}.
Recall from \cref{eq:pl.vector_from_matrix} that we obtain the recovery of the signal vector ${x}^\sharp$ from the minimizer ${X}^\sharp$ of the PhaseLift program~\cref{eq:pl.PhaseLift} via an eigenvalue decomposition.
In~\cite{Candes_2012_Solving} it was shown that \cref{eq:pl.noisy_recovery_bound} implies
\[
  \min_{0 \leq \phi \leq 2 \pi} \, \| {x}^\sharp - \mathrm{e}^{\ii \phi} {x} \|_{\ell_2}
  \leq C'' \frac{\| \epsilon \|_{\ell_1} }{m \| {x} \|_{\ell_2}}
, \label{eq:vectorial_noisy_bound}
\]
where $C''$ again denotes another constant of sufficient size.
In words, we are able to recover the original signal $x$ up to a global phase and up to an error that is determined by the signal-to-noise ratio.


\subsection{Characterization via PhaseLift}
\label{sub:pl.characterization}

In this section, we are going to connect the phase retrieval and the characterization problem.
The measured intensity at detector $j$ as given by \cref{eq:pl.intensities} exclusively provides us with information about the $j$-th row vector of ${M}$:
\[
  I_j({\alpha})
  = \left| \sum_{k=1}^n M_{j,k} \alpha_k \right|^2 + \epsilon_j
  = \left\vert  \langle {M}_j, \alpha \rangle  \right\vert^2 + \epsilon_j. \quad 1 \leq j \leq n
  \label{eq:pl.intensities_as_overlap}
\]
Here, we have defined ${M}_j$ as the (complex conjugated) row vectors of ${M}$.
Since the measured intensities in \cref{eq:pl.intensities_as_overlap} exactly resemble the measurement model of the phase retrieval problem in \cref{eq:pl.phase_retrieval_measurements}, we can use the ideas introduced in \cref{sec:pl.phase_retrieval}.
For this purpose, we propose the following protocol:
\begin{enumerate}
  \item sample $m$ random coherent input states $\ket{ \alpha^{(l)}}$ from an appropriate ensemble,
  \item measure the $m \times n$ intensities $I_1(\alpha^{(l)}), \ldots, I_n ( \alpha^{(l)})$ with $l=1,\ldots,m$, and
  \item use PhaseLift~\eqref{eq:pl.PhaseLift} to recover each ${M}_j$ individually.
\end{enumerate}

In \cref{sub:pl.recr}, we introduced different viable ensembles to sample from.
However, not all of these are equally well suited for the problem at hand.
First and foremost, since the norm of a coherent state vector $\ltwonorm{\alpha}$ describes its intensity, it is easier to prepare a state with fixed intensity with the setup from \cref{fig:experimental.schematic}.
Otherwise, one would need to introduce an additional mode to redirect \quotes{extraneous} intensity or vary the output power of the laser.
Furthermore, since the experimental implementation presented in \cref{sec:pl.optics} estimates the intensities from single photon counting rates, $\ltwonorm{\alpha}$ corresponds to the total probability of measuring a photon, and hence, should be fixed to one.

As already mentioned in \cref{sub:pl.recr}, the RECR sampling scheme was conceived with our application in linear optics in mind.
One major drawback of the uniform scheme is that each component may take any possible value for its complex phase.
In contrast, the RECR scheme has only four possible value for the phase shift, namely $\frac{k \pi}{2}$ for $k=1,\ldots,4$.
Therefore, the reconfigurable phase shifters in the implementation outlined in \cref{fig:experimental.schematic} could in principle be calibrated to these values.
A similar argument applies to the magnitudes of the RECR components, which only assume one in $n$ values.
However, the current linear architecture does not benefit from this additional constraints.
Using a tree-like structure in the preparation stage could further improve the practical performance of the PhaseLift reconstruction using RECR vectors.\\



The rest of this section is devoted to adapting the results from \cref{sub:pl.recr} to derive rigorous performance guarantees for \cref{prot:pl.detailed_reconstruction}.
Unfortunately, we currently have no proof of \cref{prop:gauss+recr_requirements} -- and hence for the recovery guarantee in \cref{thm:pl.phaselift_noisy} -- for the normalized RECR ensemble used in the experiments
Instead, we show in \cref{sec:pl.normalized_recr} how to bootstrap said theorem proven for the unnormalized version.
Since this would complicate the following discussion, we are only going to consider the uniform scheme in the remainder of this section, which provides performance guarantees for the rigorous version of the protocol suggested above

\begin{protocol}[\emph{Reconstruction of the transfer matrix ${M}$}]%
  \label{prot:pl.detailed_reconstruction}
  Let ${M}$ be an arbitrary $n \times n$ transfer matrix as defined in~\eqref{eq:pl.coherent_transfer_matrix}.
  In order to approximately recover it, sample $m = Cn$ random coherent input states $\ket{{\alpha}^{(1)}},\ldots,\ket{{\alpha}^{(m)}}$ uniformly from the unit complex sphere and measure the $mn$ intensities
  \[
    y_j^{(l)} = \left| \sum_i M_{j,i} \, \alpha_i^{(l)} \right|^2 + \epsilon_j^{(l)} \quad \forall 1 \leq j \leq n, \quad 1 \leq l \leq m,
  \]
  where $\epsilon_j^{(l)}$ denotes the additive noise at detector site $j$ when measuring the intensity resulting from input state  $\ket{{\alpha}^{(l)}}$.
  For each $1 \leq j \leq n$, solve the semi-definite program
  \begin{align}
    {Z}^\sharp_{j} = \underset{{Z} \in \Hermitian^n}{\argmin}& \quad \sum_{l=1}^m \left| \tr \left( (|{\alpha}^{l} \rangle \langle {\alpha}^{(l)} | )  Z \right) - y_j^{(l)} \right| \label{eq:tmat_recovery_program}\\
    \mathrm{subject to} & \quad {Z} \geq 0 \nonumber
  \end{align}
  and let ${M}_j^\sharp$ be the eigenvector of ${Z}^\sharp_{j}$ corresponding to its largest eigenvalue and rescaled to have length $\norm{{M}_j^\sharp}_{\ell_2} = \sqrt{ \| {Z}^\sharp_{j} \|_\infty}$.
  Then, the we estimate ${M}$ by
  \[
    {M}^\sharp =
    \begin{pmatrix}
      \adj{{M^\sharp}_1} \\ \vdots \\  \adj{{M^\sharp}_n}
    \end{pmatrix}.
    \label{eq:pl.transfermat_estimator}
  \]
\end{protocol}

Note that \cref{eq:pl.transfermat_estimator} simply amounts to stacking the separately recovered row vectors $ M_j^\sharp$.
The additional complex conjugation by taking the adjoint is due to the definition of $ M_j$ below \cref{eq:pl.intensities_as_overlap}.

Now, a simple extension of \cref{thm:pl.phaselift_noisy} yields a similar performance guarantee for \cref{prot:pl.detailed_reconstruction}:
Due to the similarity of the intensity measurements~\eqref{eq:pl.intensities_as_overlap} for a single row $M_j$ of the transfer matrix and the measurements assumed in \cref{thm:pl.phaselift_noisy}, the latter guarantees recovery of said row with high probability by means of PhaseLift~\eqref{eq:pl.PhaseLift}.
In order to succinctly state the final result, we introduce some additional notation.
Define the total noise at detector site $j$ (measured in $\ell_1$-norm) to be
\[
  \epsilon_j^{\mathrm{tot}}= \sum_{l=1}^m \abs{\epsilon_j^{(l)}}
  \label{eq:pl.error_term_summand}
\]
and the overall noise strength:
\[
  \epsilon^{\mathrm{tot}} = \sqrt{ \sum_{j=1}^n {\epsilon_j^{\mathrm{tot}}}^2}.
\]
Note that this formulation allows to treat the different output modes and their detector noise levels individually.
In particular, we do not require a universal type of noise for all detectors, but allow for taking into account detector dependent noise of different quality (i.e.\ varying noise levels).

\begin{corollary}[Performance guarantee for Protocol~\ref{prot:pl.detailed_reconstruction}]%
  \label{cor:pl.performance_guarantee}
  The reconstruction ${M}^\sharp$ of any transfer matrix ${M}$ by means of Protocol~\ref{prot:pl.detailed_reconstruction} satisfies
    \[
      \min_{{\mu}: \abs{\mu_j} = 1} \left\|  {M}^\sharp -  \mathrm{diag}(\mu_1,\ldots,\mu_n) {M} \right\|_2
      \leq C \frac{n \epsilon^\mathrm{tot}}{m \nu}.
      \label{eq:pl.total_bound}
    \]
  with probability at least $1 - \Order \left( \mathrm{e}^{-\gamma m}\right)$.
  Here, $C$ is a constant of sufficient size and
  \[
    \nu = \min_{1 \leq j \leq n} \| {M}_j \|_{\ell_2}.
    \label{eq:pl.definition_normconst}
  \]
\end{corollary}
Recall that $\mathrm{diag}(\mu_1, \ldots, \mu_n)$ are the row-phases of ${M}$ unrecoverable from the measurements~\eqref{eq:pl.intensities}.
We include the additional correction~\eqref{eq:pl.definition_normconst} to deal with possible loss, since for unitary transfer matrices we have $\nu = 1$.

\begin{proof}
For any fixed row vector ${M}_j$,
\[
  \min_{0 \leq \phi \leq 2 \pi}\left\| {M}_j^\sharp - \mathrm{e}^{i \phi} {M}_j \right\|_{\ell_2} \leq C' n \min
  \left\{
  \| {M}_j \|_{\ell_2}, \frac{ \epsilon_j^{\mathrm{tot}}}{m \| {M}_j \|_{\ell_2}}
  \right\}.
  \label{eq:noisy_reconstruction_vectorial_bound}
\]
follows directly from \cref{thm:pl.phaselift_noisy}.
Note that the additional $n$ factor compared to \cref{eq:vectorial_noisy_bound} is due to the normalization of the input vectors.
As shown in \cref{prop:gauss+recr_requirements}, the input vectors sampled uniformly from the complex unit sphere need to be scaled by $\sqrt{n}$ in order to satisfy \cref{eq:pl.tight_frame,eq:pl.sub_isotropy,eq:pl.subexponential}.

Before we can move on to determine the remaining row vectors ${M}_{i}$ ($i \neq j$) of ${M}$, it is important to point out that the recovery guarantee of \cref{thm:pl.phaselift_noisy} is \emph{universal}: one instance of randomly chosen measurement vectors suffices to recover \emph{any} vector ${x} \in \Complex^n$.
This allows for applying this reconstruction guarantee to all $n$ row vectors ${M}_j$ simultaneously.
The total noise bound~\eqref{eq:pl.total_bound} now follows from the entry-wise definition of the Frobenius norm:
\begin{align}
  \min_{{\mu}}\left\|  {M}^\sharp -  {D} ({\mu}) {M} \right\|_2 ^2
  &= \min_{0 \leq \phi_1,\ldots,\phi_n \leq 2 \pi}
  \sum_{j=1}^n \left\| {M}_j^\sharp - \mathrm{e}^{i \phi_j} {M}_j \right\|_{\ell_2}^2 \\
  &= \sum_{j=1}^n \min_{0 \leq \phi_j \leq 2 \pi} \left\| {M}_j^\sharp - \mathrm{e}^{i \phi_j} {M}_j \right\|_{\ell_2}^2 \\
  & \leq C^2 n^2 \sum_{j=1}^n  \min \left\{ \| {M}_j \|_{\ell_2}^2, \frac{ \eta_{(j)}^2}{m^2 \|{M}_j \|_{\ell_2}^2} \right\} \\
  &\leq \left(C n\right)^2 \sum_{j=1}^n \frac{\eta_{j}^2}{m^2 \|{M}_j \|_{\ell_2}^2} \\
  & \leq \frac{\left(Cn \right)^2}{m^2 \nu} \sum_{j=1}^n \eta_{j}^2 \\
  &= \left( C n \frac{\eta^{\mathrm{tot}}}{m \nu} \right)^2,
\end{align}
Here, we have used \eqref{eq:vectorial_noisy_bound} for each summand in the third line.
\end{proof}


The performance guarantee above has an interesting consequence for experimental design:
The right hand side of \cref{eq:pl.total_bound} is mainly determined by the signal-to-noise ratio $\frac{\nu}{\epsilon^\mathrm{tot} / m}$.
Remarkably, the noise term does not become smaller when $m$ is increased.
To be more precise, let us assume that each detection error  is independent and normally distributed with standard deviation $\sigma$, i.e.\ $\epsilon\ind{l}_j \sim \Normal(0, \sigma^2)$.
Then,
\[
  \Exp \epsilon^\mathrm{tot}_j = \frac{1}{m} \sum_j \Exp \epsilon\ind{l}_j = \Exp \epsilon\ind{1}_j = \sqrt{\frac{2}{\pi}} \sigma,
\]
and hence, the expected error $\Exp \epsilon^\mathrm{tot}$ is independent of $m$.
Of course, the standard deviation of $\epsilon^\mathrm{tot}_j$ scales as $\frac{1}{\sqrt{m}}$.
Therefore, an increase of $m$ past the threshold $Cn$ in \cref{cor:pl.performance_guarantee} mainly influences the (exponentially small) failure probability.
In other words, said corollary implies that once the sampling threshold is reached, there is not much use to further increase the number of measurements as the error bound~\eqref{eq:pl.total_bound} is then primarily determined by the uncertainty of a single measurement.
Hence, any additional experimental time should be invested to reduce the uncertainty of the single measurements, e.g.\ by increasing the number of single photon events used to estimate $I_j(\alpha)$.

By studying the assumptions and the proof of the underlying \cref{thm:pl.phaselift_noisy}, we also note that this behavior is to be expected.
Since said theorem does not assume any statistical properties of the noise, but only assumes that the noise $\epsilon\ind{l}$ is bounded, we cannot expect a statistical improvement by increasing the number of measurements.
For example, if we assume a constant, purely systematic error $\epsilon\ind{l} = c$ for all measurements, then no improvement can be expected even for $m\to\infty$.
\todo{true?}

However, it should be kept in mind that \cref{cor:pl.performance_guarantee} only provides necessary conditions for recovery, which are not optimal in the large $m$ regime.
Therefore, we perform numerical simulations in the next chapter to further investigate how experimental time should be spent.
In other words, we study the question how the reconstruction performs as a function of $m$ when the total experimental time budget is fixed.
Note that this behavior has already been explored in the context of quantum state tomography via compressed sensing in~\cite{Flammia_2012_Quantum}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Results}%
\label{sec:pl.results}

\subsection{Numerical Results}%
\label{sub:pl.results.numerics}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tbp]
  \begin{subfigure}{.475\columnwidth}
    \includegraphics[width=\linewidth]{fig/phaselift_sim_gaussian}
    \caption{\label{sfig:pl.simplot.gaussian}%
      Uniform sampling
    }
   \end{subfigure}
  \begin{subfigure}{.475\columnwidth}
    \includegraphics[width=\linewidth]{fig/phaselift_sim_recr}
    \caption{\label{sfig:pl.simplot.recr}%
      RECR sampling
    }
   \end{subfigure}
  \caption{\label{fig:pl.simplot}%
    Simulated recovery-probability using the two different sampling schemes under noisy measurements with $\sigma = 0.05$.
    For each given dimension, the transfer matrices to be recovered consist of 97 Haar random unitaries as well as the identity, the swap-matrix, and the discrete Fourier transform.
    The red line indicates the conjectured phase transition at $4 n - 4$.
  }
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

We demonstrate the practical applicability of the PhaseLift characterisation protocol using simulated experiments.
The simulation depicted in \cref{fig:pl.simplot} aims to visualize the performance guarantees from \cref{cor:pl.performance_guarantee}:
For each given dimension $n$, we choose 100 target unitaries.
Each of these is reconstructed by means of \cref{prot:pl.detailed_reconstruction} with a varying number of measurements $m$.
The input vectors are sampled from the uniform ensemble in \cref{sfig:pl.simplot.gaussian} and from the normalized RECR ensemble in \cref{sfig:pl.simplot.recr}.
For the measurement noise $\epsilon_j$ from \cref{eq:pl.intensities_as_overlap}, we assume independent, centered Gaussian noise with standard deviation $\sigma = 0.05$.
The density plots show the fraction of successfully recovered unitaries.
Here, the criterion for success is whether the distance of the reconstruction $M^\sharp$ measured in Frobenius norm is smaller than the threshold  $4 \sigma n$ in accordance with the error bound~\eqref{eq:pl.total_bound}.

\Cref{sfig:pl.simplot.gaussian,sfig:pl.simplot.recr} show a pronounced phase transition around $4n - 4$.
This demonstrates the high sample efficiency of the PhaseLift reconstruction.
Not only does the number of measurements scale linearly in the system size but the scaling coefficient is small as well.\\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tbp]
  \begin{subfigure}{.475\columnwidth}
    \includegraphics[width=\linewidth]{fig/phaselift_sim_errorscaling_dft_5}
    \caption{\label{sfig:pl.simerror.five}%
      $n = 5$
    }
   \end{subfigure}
  \begin{subfigure}{.475\columnwidth}
    \includegraphics[width=\linewidth]{fig/phaselift_sim_errorscaling_dft_10}
    \caption{\label{sfig:pl.simerror.ten}%
      $n = 10$
    }
   \end{subfigure}
  \caption{\label{fig:pl.simerror}%
    Simulated reconstruction error for the with fixed time budget as a function of the number of measurements for two different circuit sizes.
    The total photon number in for each reconstruction is $N = 4600 \times t$.
    Then, the output for each input vector $\alpha$ is a multinomial distribution with the number of trials given by $\frac{M}{m}$.
    Intensities for the PhaseLift reconstruction is estimated for 100 samples of each distribution.
    The solid line indicates the mean and the colored areas the $0.025$ and $0.975$ quantiles.
  }
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


In the simulations depicted in \cref{fig:pl.simplot}, we assumed a constant noise level for each $m$.
Therefore, the lab-time required for taking the data increases linear in $m$.
We now investigate the question posed at the end of \cref{sub:pl.characterization}, namely how the reconstruction performs as a function of $m$ when the total experimental time budget is fixed.
\todo{Fill in}
Recall from \cref{eq:pl.photon_stats} that the single photon counting statistics is given by a multinomial equation with number of trials $N$ given by the total photon number and the probabilities $p_j$ given by the expectation values in \cref{eq:pl.experiment.probabilities}.
Denote by $N\ind{l}$ the number of photons used to estimate the output intensities for a single photon input state $\ket{\psi(\alpha\ind{l})}$ with $l=1,\ldots,m$.
In \cref{fig:pl.simerror}, we depict the reconstruction error with the total number of photons used for reconstruction $N = \sum_l N\ind{l}$ kept fixed.
To be more precise, we choose the total number of photons $N$ as a multiple of the counting rate from the experiment $\Gamma = 4600\,s^{-1}$, i.e.
\[
  N = t \times \Gamma,
  \label{eq:pl.counts_from_time}
\]
where $t$ is the time spent on the whole experiment.
Therefore, we have $N\ind{l} = \frac{N}{m}$, where $m$ is the number of preparation vectors.
The reconstructions in \cref{fig:pl.simerror} are then performed by randomly sampling 100 outcomes from the output counting statistics of each input state.
For larger $m$, the $N\ind{l}$ becomes smaller, and therefore, the statistical error in each estimated intensity grows.

In \cref{fig:pl.simerror}, we see that as expected, taking more data by increasing $t$ improves the reconstruction quality.
Also note that the reconstruction error is approximately independent of $m$ above a certain threshold.
This clearly shows that the recovery guarantee in \cref{cor:pl.performance_guarantee} is not tight for larger values of $m$, as the right hand side of \cref{eq:pl.total_bound} grows with the individual statistical error of each measurement.

From \cref{fig:pl.simerror}, one could conclude that there is no advantage of taking a small value of $m$ in the experiments.
This conclusion rests on the assumption that the total number of photons is the figure of merit that best describes an experimentalist's budget.
However, in the concrete experimental architecture introduced in \cref{sec:pl.optics}, this is not the case:
In reality, the number of distinct settings for the reconfigurable chip is more critical for the time required to perform a given experiment.
This is due to the fact that switching the reconfigurable phase shifters and couplers takes more time that the actual data taking process.

\todo{finish}





\subsection{Experimental Results}%
\label{sub:pl.results.experiment}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{figure*}[tbp]
  \centering
  \includegraphics[width=0.95\textwidth]{fig/phaselift_ex_dipsref}
  \caption{%
     \label{fig:experimental.overview}
     Comparing reconstructions from experimental data for different target transfer matrices and sampling schemes.
     For each matrix and sampling scheme, we subsample $m = 5n$ preparation vectors and the corresponding measured intensities from the experimental data 100 times.
     The colored diamonds indicate the median and the colored area sketches the distribution of the discrepancy between the PhaseLift reconstruction and an alternative method.
     Since for $n=2$ there are only six distinct RECR vectors up to a global phase, there is only one reconstruction.
     In the left picture, the reference is obtained through a HOM-dip reconstruction as discussed in the appendix.
     However, since this technique is too costly for larger dimensions, the five dimensional reconstructions on the right are only compared in magnitude to a reference from single photon data neglecting all phase information.
     For more details on the data analysis see the supplemental material.
  }
\end{figure*}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tbp]
  \centering
  \includegraphics[width=\columnwidth]{fig/phaselift_ex_targetref}
  \caption{%
     \label{fig:experimental.targetref}
     Same as \cref{fig:experimental.overview}, but the reconstructions are compared to the theoretical target unitaries.
     \quotes{HOM-dip} refers to the reconstructions used as references in \cref{fig:experimental.overview}.
     We do not show the results for the 5 dimensional unitaries since the corresponding HOM-dip reconstructions were too costly to take.
  }
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{figure*}[tbp]
  \centering
  \includegraphics[width=0.95\columnwidth]{fig/phaselift_ex_details}
  \caption{%
    \label{fig:experimental.details}
   Reconstruction errors for a random $5 \times 5$ matrix from experimental data.
   For each picture, we plot the mean (solid) as well as min- and max- errors over 25 samples.
   In the left picture, each sample consists of a recovery from $m$ preparation vectors and the corresponding photon counts measured over $t = 30\,hrm{s}$
   In the right picture, we fix a randomly selected set of $m=20$ preparation vectors and run the recovery with the photon counts from $t$ randomly selected time bins, each of which is one second long.
  }
\end{figure*}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

To demonstrate its practical utility, we used the PhaseLift protocol to perform experimental reconstruction on the reconfigurable integrated photonic circuit introduced in \cref{sec:pl.optics}
In \cref{fig:experimental.overview}, we show the discrepancy of the PhaseLift recoveries compared to the experimental reconstruction via Hong-Ou-Mandel dips (HOM-dips), which is described in detail in \cref{sec:???}.
Since our aim is to benchmark the performance of the PhaseLift characterization, and not the performance of the chip itself, we compare to reconstructions obtained through established but more costly techniques: for the smaller transfer matrices of dimension two and three, we perform a complete HOM-dip-reconstruction based on two photon interference.
However, since this is infeasibly costly for the five-dimensional transfer matrices, we only compare these to single-photon reconstructions of the absolute values of the transfer matrix components.
Therefore, for the larger transfer matrices, we neglect the phase information of the alternative reconstruction.

The number of input vectors used in each PhaseLift reconstruction is $m = 5n$.
This slight overhead compared to the numerically conjectured phase transition in \cref{fig:pl.simplot} is used to counteract systematic errors in the generation of the random vectors, which we conjecture to be the main source of error in this experiment.
We see that the PhaseLift reconstructions and the references agree well for most settings in \cref{fig:experimental.overview}
Even without exploiting the possible advantages of the RECR ensemble due to a better calibration, it generally performs as well as the uniform ensemble.
Both display a similar behavior: for a fixed number of modes, the deviations are generally larger for the random unitaries compared to the more structured identity and Fourier transfer matrices.
Also, the errors for the two-dimensional transfer matrices are slightly smaller than for the corresponding three-dimensional transfer matrices as expected from \cref{eq:pl.total_bound}.
Furthermore, the currently used sequential arrangement of the MZIs in the preparation stage of the experiment also leads to higher reconstruction errors with an increase in dimension -- possible solutions to this problem are discussed in the conclusions.
For the reference reconstruction, we also expect larger deviations with an increase in the size of the transfer matrix, since errors in the phases of the components accumulate.
Note that the errors for the five-dimensional transfer matrices are relatively small since they only take into account the absolute values of the components and neglect all phases.

In \cref{fig:experimental.targetref} we directly compare the performances of the reconstruction protocols, namely of the PhaseLift reconstruction and the HOM-dip reconstruction.
In contrast to \cref{fig:experimental.overview}, here we use the theoretical target unitary as a reference.
Generally, the errors of the PhaseLift reconstructions and the HOM-dip reconstructions are of the same order of magnitude.
This is despite the fact that the HOM-dip reconstruction is not just insensitive to the row phases, but also to the column phases.
Therefore, the reported errors for the HOM-dip reconstruction are minimized over both row- and column phases instead of just the row phases for the PhaseLift reconstruction.
The additional free parameters in the minimization may lead to overfitting, and hence, to an underestimation of the actual error of the HOM-dip reconstruction.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Conclusion and Outlook}

\todo{Fix this}
In this work, we introduce a solution to the problem of characterizing linear optical devices based on recent advances in phase retrieval and low-rank matrix recovery.
The PhaseLift reconstruction outlined in \cref{prot:pl.detailed_reconstruction} can be used to reconstruct any transfer matrix using only intensity measurements and classical states of light as inputs, which are chosen at random from an appropriate ensemble.
Not only do the number of measurements required for this approach scale linearly in the number of modes of the device, the theory behind it also provides stringent error bars for the reconstruction.
As the major contribution of this work, we proof recovery guarantees for the RECR ensemble, which is especially suited for the application in linear optical devices.
We also report on a successful experimental implementation of the PhaseLift characterisation protocol based on a universally reconfigurable six waveguide device.
The results from this experiment show that although the experimental effort of our approach is much lower, it provides a similar performance compared to other characterisation techniques.

\todo[inline]{@Bristol: Your future work?}
Another possible extension of the experimental work is the development of a dedicated state-preparation circuit.
In the current architecture, possible errors in the preparation state for the coherent state inputs $\ket{\alpha}$ add up linearly due to the serial wiring in the preparation stage.
With a tree-like arrangement of the directional couplers, we might be able to also benefit from the fact that the RECR scheme allows only for two possible values for the intensity of each input mode $\abs{\alpha_i}$.
