 % -*- root: ../thesis.tex -*-
\chapter{Uncertainty Quantification for quantum state estimation}
\label{chap:error}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Introduction to Statistics}
\label{sec:error.intro}

% two main flavours of statistics...
% task of parameter estimation, model
% parametric model: state space \Omega
However, even if our model describes the data perfectly we cannot exactly recover this value from a finite amount of data due to statistical fluctuations.
The concept of error bars, or more generally error regions, allows for quantifying the uncertainty of a given estimate. 

% uncertatiny quantification, problem with point estimators

\subsection{Frequentist Statistics}
\label{sub:intro.frequentist}

In the frequentist (or orthodox) framework, the probability of an outcome of a random experiment is defined in terms of its relative frequency of occurrence when the number of repetitions goes to infinity~\cite{Keynes_2007_Treatise,Kiefer_2012_Introduction}.
More precisely, denote the number of repetitions of an experiment by $T$ and the number of times the event under consideration $x$ occurred by $n_T$. 
Then, a Frequentist interprets the probability $\Prob(x)$ as the statement that if $T \to \infty$, $\frac{n_T}{T} \to \Prob(x)$.

% probabliities = hypothetical frequencies, not repeatable
For the task of parameter estimation, we assume that the observed data are generated from the parametric model with \quotes{true} parameter $\Theta \in \Omega$, which is unknown.
From a finite number of observations $X_1, \ldots X_N$, we must construct an estimate for $\Theta$ that is close to the true value in some sense.
The function $\hat\Theta$ that maps observations to such an estimate is called a point estimator.
The quality of an estimator is measured by its risk function.
A risk function commonly used for continuous parameter spaces is the mean square error
\[
  \label{eq:frequentist.mean_square}
  \mathcal{L}_{\hat\Theta}(\Theta) := \Exp_\Theta \left( \Norm{\Theta - \hat\Theta(X_1, \ldots, X_N)}^2 \right).
\]
\todo{Make loss without expectation}
Note that \cref{eq:frequentist.mean_square} -- and therefore the performance of a given estimator -- still depends on the unknown true value $\Theta$.
Strategies to make statements independent of the true value include 
\begin{definition}
  \label{def:frequentist.optimality_conditions}
  \begin{itemize}
    \item $\hat\Theta$ is called a \emph{uniformly best} estimator, if for all other estimators $\hat\Theta'$ and all values of the true parameter $\Theta \in \Omega$
    \[
      \mathcal{L}_{\hat\Theta}(\Theta) \le \mathcal{L}_{\hat\Theta'}(\Theta).
    \]

    \item $\hat\Theta$ is called \emph{minimax}, if for all other estimators $\hat\Theta'$
    \[
      \sup_{\Theta\in\Omega} \mathcal{L}_{\hat\Theta}(\Theta) \le \sup_{\Theta\in\Omega} \mathcal{L}_{\hat\Theta'}(\Theta).
    \]

    \item $\hat\Theta$ is called \emph{best on average} w.r.t.\ a distribution of the true value $\Theta$ if for all other estimators $\hat\Theta'$
    \[
      \Exp_{\Theta} \mathcal{L}_{\hat\Theta}(\Theta) \le  \Exp_{\Theta} \mathcal{L}_{\hat\Theta'}(\Theta).
    \]

    \item $\hat\Theta$ is called \emph{admissible} if there is no other estimator $\hat\Theta'$ such that
    \[
      \forall\Theta \in \Omega\colon \mathcal{L}_{\hat\Theta'}(\Theta) \le \mathcal{L}_{\hat\Theta}(\Theta) 
      \quad\mbox{ and }\quad
      \exists\Theta \in \Omega\colon \mathcal{L}_{\hat\Theta'}(\Theta) < \mathcal{L}_{\hat\Theta}(\Theta) 
    \]
  \end{itemize}
\end{definition}
\todo{Citation}
\todo{Discussion of different properties, why no expectation value -> no "singular" regions?}
\todo{Choice is arbitrary!}
\todo{How does this connect with definition of probability?}
\todo{Typical estimators? Max likelihood?}
\todo{No statement about single runs!}


% examples (also depends on notion of volume), admissability
However, as already mentioned in the introduction, point estimators cannot convey uncertainty in the estimate. 
For this purpose we need to introduce a precise notion of \quotes{error bars}, namely \emph{confidence regions}.
A confidence region $\CR \subset \Omega$ with coverage $\alpha \in [0,1]$ is a region estimator -- that is a function that maps observed data to a subset of the parameter space -- such that the true parameter is contained in $\CR$ with probability greater than $\alpha$
\[
  \label{eq:frequentist.coverage}
  \forall \Theta\in\Omega \colon \Prob_\Theta\left( \CR(X_1, \ldots, X_N) \ni \Theta \right) \ge \alpha.
\]
\todo{Make this explicit defintion?}
Similar to point estimators, \cref{eq:frequentist.coverage} does not uniquely determine a confidence region construction.
Furthermore, additional constraints are necessary to exclude trivial constructions such as the following:
Take the region estimator, which is always equal to the full parameter space independent of the data $\CR(X_1, \ldots X_N) = \Omega$, then 
\[
  \Prob_\Theta\left(  \CR(X_1, \ldots, X_N) \ni \Theta  \right) = 1 \ge \alpha
\]
for all confidence levels $\alpha$.
Although, this construction trivially fulfils the coverage condition~\eqref{eq:frequentist.coverage}, it does not provide useful information on the uncertainty as it does not restrict the parameter space at all.
Therefore, we have to impose a notion of what constitutes a good confidence region.

Clearly, if we have two confidence regions $\CR_1$ and $\CR_2$ with the same confidence level $\alpha$ and $\CR_1 \subset \CR_2$, then $\CR_1$ is more informative.
More generally, smaller regions should be preferred since they convey more confidence in the estimate and exclude more alternatives.
Therefore, measures of size such as (expected) volume or diameter are commonly used as risk functions for region estimators.
This leads to similar definitions as in \cref{def:frequentist.optimality_conditions} for confidence regions with the additional constraint that \cref{eq:frequentist.coverage} has to be fulfilled.

\todo{Today: Asymptotic optimal, adaptive, ...}


\subsection{Bayesian Statistics}
\label{sub:intro.bayesian}

% frequentist: parameters fixed, data random; Bayesian: other way
% two different camps of interpretation: subjective and objective -> only differetnt in interpretation, technically the same
% prior -> Bayes' rule -> posterior 

Let us now introduce the Bayesian point of view on inference.
In contrast to the Frequentist's framework, where the existence of a single \quotes{true value} for the model parameter is assumed and the observed data is assumed to be random, Bayesian statistics treats the parameter itself as a random variable.
More precisely, in Bayesian statistics probabilities reflect subjective beliefs and allow for consistently updating one's belief according to empirical observations.
In a parameter estimation problem, the \emph{prior distribution} $\Prob(\Theta)$ expresses one's belief about the parameter $\Theta$ before taking any data into account.
Given an observation $X$, the distribution of $\Theta$ is updated according to Bayes' rule~\cite{}
\[
  \label{eq:bayesian.bayes_rule}
  \Prob(\Theta | X) = \frac{\Prob(X | \Theta) \Prob(\Theta)}{\Prob(X)}.
\]
Here, $\Prob(X|\Theta)$ is the \emph{likelihood function} and $\Prob(\Theta | X)$ is the \emph{posterior distribution} -- or short posterior -- of $\Theta$.

% posterior encodes all information
% but if one wants to report single number: Bayes mean estimator -> Bregman divergences -> optimality
% also MAP estimator -> optimization problem, often used due to efficency
Note that the posterior contains all the information on $\Theta$. 
To summarize important features of the posterior, we introduce point and region estimators similar to the Frequentist case:
One commonly used estimator is the Bayesian mean estimator (BME) given by
\[
  \hat\Theta_\mathrm{BME}(X) = \int \Theta \, \Prob(\Theta | X) \, \dd\Theta.
\]
A justification for the BME is that it minimizes (under normal circumstances~\cite{Lehmann_1998_Theory}) the expected loss 
\[
  \label{eq:bayesian.expected_loss}
  \Exp_\Theta \mathcal{L}(\Theta, \hat\Theta(X)),
\]
provided the loss function $\mathcal{L}$ is a \emph{Bregman divergence}~\cite{Banerjee_2005_On}.
Note that the expectation over $\Theta$ in \cref{eq:bayesian.expected_loss} is taken over the posterior with observation $X$.

Another example of a point estimator is the \emph{maximum a posteriori} (MAP) estimator.
As the name suggests, the MAP estimator is obtained by maximizing the posterior~\eqref{eq:bayesian.bayes_rule}.
Since this does not require the expensive computation of the denominator in \cref{eq:bayesian.bayes_rule} and (at least local minima) of the posterior can be found efficiently via gradient descent, the MAP estimator is often used in high dimensional problem~\cite{Murphy_2012_Machine}.\\

% uncertainty quantificatio -> credible region 
% since for given outcome everythign fixed, less arbitrary/freedom then frequentist (see Def. above)
% min. vol, least surprise, ...



% conjugated priors