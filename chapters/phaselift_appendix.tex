% -*- root: ../thesis.tex -*-
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\chapter{Phaselift}
\label{cha:phaselift_appendix}

\section{Experimental Details}%
\label{sec:pl.experimental_details}

\todo{Keep this section?}

\subsection{Reference Reconstructions}%
\label{sub:pl.hom_dip}

Since our goal is to benchmark the PhaseLift characterisation technique, and not the performance of the optical chip, we compare the experimental reconstructions to reconstructions obtained with a different technique.
These reference reconstructions are obtain in two steps.
First, we estimate the absolute value of each component from single photon data:
From \cref{eq:pl.intensities}, we see that by inserting single photons into the $k$-th input of the device -- that is choosing the standard basis vectors as inputs $\alpha =  e_k$ as inputs --  we can estimate $\abs{M_{i,k}}$.
For each input port, the counts of each detector are normalised to take into account the detector efficiencies and then divided by the total of the counts in all detectors.
The square roots of these numbers are used as the estimated amplitudes of the matrix elements.
Second, we estimate the phase of each component using HOM-dips~\cite{Hong_1987_Measurement}, following a similar approach to~\cite{Laing_2012_SuperStable,Dhand_2016_Accurate}.
However, this second step is time-consuming and only reliable for small devices.
Therefore, for the larger devices, we only perform the first step and compare only the magnitudes of the matrix elements of the reconstructions.

To perform the HOM experiments, the preparation-stage MZIs marked red in \cref{fig:experimental.schematic} were set to perform an identity transformation and both fibres carrying the photon pairs generated by the source were connected to input ports of the chip.
For each pairwise combination of the input modes of our matrices, we recorded the twofold coincidences among our detectors while changing the time delay of a photon relative to the other via a motorised translation stage.
The difference in coincidence counts as a function of delay were fit to the function:
\[
  f(\tau)=\left(1-c_1\exp[-((\tau - c_2)/c_3)^2]\mathrm{sinc}[(\tau - c_2)/c_6]\right)(c_4\tau + c_5 + c_7 \tau^2)
\]
where $\tau$ is the time delay of the photon and $\{c_i\}$ fit parameters.
The first term approximates the temporal envelope of a Gaussian photon subject to a top-hat filter and the second term adjusts for the decoupling resulting from the movement of the translation stage.
From the coefficient $c_1$ of this fit we retrieve a bare visibility of the two photon interference.
These bare visibilities are then rescaled by a reference visibility that accounts for the partial-distinguishability of the photons in their remaining degrees of freedom.
This was periodically assessed by implementing an effective 50:50 beam splitter on the chip and observing dip visibilities ranging from 0.965 and 0.985.

In order to retrieve the phase information of the matrix elements, the two photon interference fringes with the best estimates of the visibility were selected for each matrix to create a sequence that suffices to determine the phases of all the elements of the matrix.
Assuming that all the elements of the first row and of the first column are real and positive, the complex argument of the first phase factor retrieved associated to the element $M_{ij}$ is given by the following equation.
\[
\phi_{ij}=\pm  \arccos\left( - \frac{|M_{1,1}M_{i,j}|^2+|M_{1,j}M_{i,1}|^2}{2 |M_{1,1}M_{i,j}M_{1,j}M_{i,1}|} V_{1,j,1,i} \right)
\]
where $V_{1,j,1,i}$ is the visibility observed injecting photons into the ports 1 and j and detecting photons at the output ports 1 and i.
The sign $\pm$ in the equation is chosen to maximise the similarity to the target matrix.
Then, if we want to use a visibility $V_{\beta,j,\alpha,i}$ to deduce the phase $\phi_{ij}$ knowing $\phi_{\alpha \beta}$, $\phi_{\alpha j}$ and $\phi_{i \beta}$ we have
\[
\phi_{ij}=\pm   \arccos\left( - \frac{|M_{\alpha \beta}M_{i,j}|^2+|M_{\alpha,j}M_{i,\beta}|^2}{2 |M_{\alpha,\beta}M_{i,j}M_{\alpha,j}M_{i,\beta}|} V_{\beta,j,\alpha,i} \right) +\phi_{\alpha j} +\phi_{i \beta} -\phi_{\alpha \beta}
\]



\subsection{Data Analysis}%
\label{sub:pl.data_analysis}

\begin{table}
  \begin{tabular}{l | r r r}
    Dimension $n$ & 2 & 3 & 5 \\
    Gaussian & 20 & 30 & 40 \\
    RECR & 6 & 31 & 39 \\
  \end{tabular}
  \caption{%
    \label{tab:measurements}
    Total number of preparation vectors taken during experiment.
  }
\end{table}

As mentioned in the main text, we estimate the intensity measurements from single photon counting rates.
After correcting for detector efficiency, all counting rates are scaled by a constant such that the resulting intensities obey $\max_l \sum_j I_j(\alpha^{(l)}) = 1$.
This only amounts to scaling the transfer matrix by a constant, which does not influence the end result since we later rescale the obtained reconstruction appropriately (see \cref{eq:pl.experimental_details.data.scaling}).
However, this simple rescaling helps with numerical stability in the SDP solver.
We provide a ready for use implementation of the PhaseLift convex program~\eqref{eq:pl.PhaseLift} as well as related algorithms in the open source library \textsc{pypllon}~\cite{Suess_2017_Pypllon},

The post-processing of a reconstruction ${M}^\sharp$ consists of two steps:
First, we rescale the reconstruction by a constant such that
\[
  \label{eq:pl.experimental_details.data.scaling}
  \max_i \norm{(M^\sharp)_i}_{\ell_2} = 1,
\]
where $(M^\sharp)_i$ denotes the $i$-th row of $M^\sharp$.
In an ideal experiment, $M^\sharp$ would be unitary and, therefore, every row would have unit norm.
However, due to loss in the characterised circuit as well as detector inefficiencies, the norm of each row is smaller than one.
Since we cannot distinguish the two sources of loss in our current experimental setup, we cannot characterise the absolute photon loss in the circuit, but only the relative losses of the rows.
Estimating the dark counts in future experiments would enable characterising the absolute photon loss in the circuit as well.

The second post-processing step consists of fixing phases of the reconstructions:
Recall that we are only able to recover the transfer matrix up to its row phases since the global phases of the rows are lost in the intensity measurements.
Therefore, we fix the row phases of the PhaseLift reconstructions in \cref{fig:experimental.targetref} by minimizing the Frobenius distance to the target unitary and compute the error as
\[
  \min_{{\mu}: \abs{\mu_i} = 1}\left\|  {M}_\mathrm{target} -  \mathrm{diag} ({\mu}) {M}^\sharp) \right\|_2
\]
However, since the HOM-dip reconstruction is insensitive to global phases of the columns as well, we have to minimize both row and column phases for the HOM-dip reconstructions in \cref{fig:experimental.targetref}.
Furthermore, since in \cref{fig:experimental.overview} the HOM-dip reconstruction is taken as reference value, we have to minimize the row and column phases for all PhaseLift reconstructions in that picture as well.
The raw data as well as the analysis scripts are available at \url{https://github.com/dseuss/phaselift-paper}.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\section{Proof of \cref{thm:pl.phaselift_noisy}}%
\label{sec:pl.main_proof}

In this section we present a proof for the phase retrieval recovery guarantees in \cref{thm:pl.phaselift_noisy}.
Note that equally strong recovery guarantees are well-established for the Gaussian and uniform ensemble\cite{Candes_2012_Solving,Demanet_2014_Stable}.
However, to keep this work self-contained we present a unified proof for all sampling schemes from \cref{prop:gauss+recr_requirements}.
Our analysis is inspired by Ref.~\cite{Dirksen_2017_On} (who derived strong results for sparse vector recovery using similar assumptions) and Ref.~\cite{Kabanava_2015_Stable} in the non-commutative setting.
Moreover, Krahmer and Liu considered a real-valued version of the problem addressed here~\cite{Krahmer_2018_Phase}.


\subsection{Mathematical preliminaries}

Our analysis is based on two fundamental results in random matrix theory.
First, the assumption of subgaussian tails~\eqref{eq:pl.subexponential} implies strong bounds on the operator norm of matrices of the form $\sum_{k=1}^m \ketbra{\alpha\ind{l}}$:

\begin{theorem}[Variant of Theorem 5.35 in~\cite{Vershynin_2010_Introduction}]%
  \label{thm:bernstein}
  Suppose that $\alpha\ind{1},\ldots,\alpha\ind{m}$ are independent copies of a subgaussian random vector obeying \cref{eq:pl.subexponential} with constant $C_\mathrm{SG}$.
  Let
  \[
    \tilde{ H} = \frac{1}{m} \sum_{k=1}^m \left( a_k \ketbra{\alpha\ind{l}} - \mathbb{E} \left[ a_k \ketbra{\alpha\ind{l}} \right] \right),
    \label{eq:pl.Htilde}
  \]
  where $a_k \in \mathbb{C}$ and $\abs{a_k} \leq 1$.
  Then,
  \begin{align}
    \Prob \left[ \opnorm{\tilde{ H}} \geq t \right]
    \leq
    \begin{cases}
      2 \exp \left( 2 \ln (3) n  - \frac{mt^2}{8 C_\mathrm{SG}} \right) & 0 \leq t \leq 2C_\mathrm{SG}, \\
      2 \exp \left( 2 \ln (3) n - \frac{m}{2} \left( t - C_\mathrm{SG} \right)  \right) & t \geq 2 C_\mathrm{SG},
    \end{cases}
  \end{align}
  where $\opnorm{\cdot}$ denotes the operator norm.
\end{theorem}


The second result is a generalization of \quotes{Gordon's escape through a mesh}-Theorem \cite{Gordon_1988_On} (a random subspace avoids a subset provided the subset is small in some sense).
The version we use here is due to Mendelson~\cite{Mendelson_2015_Learning,Koltchinskii_2015_Bounding}, see also see also \cite{Tropp_2014_Convex}.

\begin{theorem}[Mendelson's small ball method]%
  \label{thm:mendelson}
  Suppose that the measurement operator $\mathcal{A}:\Hermitian^n \to \mathbb{R}^m$ contains $m$ independent copies $A\ind{l}$ of a random matrix $ A \in \Hermitian^n$, that is
  \[
    \label{eq:pl.measurement_operator_definition}
    \mathcal{A}(Z) = \sum_{l=1}^m \tr (A\ind{l}  Z) \,  {e_l}
  \]
  with $e_l$ denoting the $l$-th canonical basis vector.
  For $D \subset \Hermitian^n$ and $\xi >0$ define
  \begin{align}
    Q_\xi (D,  A) =& \inf_{ Z \in D}\Prob \left[ | \tr (A\ind{l}  Z) | \geq \xi \right] \quad &\textrm{(marginal tail funtion)}, \label{eq:pl.marginal_tail_function}\\
    W_m (D,  A) =& 2 \, \mathbb{E} \left[ \sup_{ Z \in D} \tr \left(  Z  H \right) \right] \quad &\textrm{(mean empirical width)},
  \end{align}
  where
  \[
    H= \frac{1}{\sqrt{m}} \sum_{l=1}^m \eta_l A\ind{l}.
  \]
  Here, the $\eta_l$ are independent Rademacher random variables, i.e.\ $\Prob(\eta_l = 1) = \Prob(\eta_l=-1) = \frac{1}{2}$.
  Then for any $\xi >0$ and $t >0$
  \[
    \frac{1}{\sqrt{m}}\inf_{ Z \in D} \| \mathcal{A}( Z) \|_{\ell_1} \geq \xi \sqrt{m} Q_{2\xi}(D,  A) -  W_m (D,  A)-\xi t \label{eq:pl.mendelson}
  \]
  with probability at least $1-\mathrm{e}^{-2t^2}$.
\end{theorem}

Note that the measurement operator introduced in \cref{eq:pl.measurement_operator_definition} is a shorthand notation for the linear measurements $y\ind{l} = \tr  \left( A\ind{l}  Z \right)$ with $l=1,\ldots,m$.
It maps the signal matrix $Z$ to the vector of (noiseless) measurement outcomes $\sum_l y_l \, {e_l}$.\\


The following two propositions summarize several results presented in \cite{Kabanava_2015_Stable} and adapt them to the problem of phase retrieval.

\begin{proposition}%
  \label{prop:nsp_implication}
  Let $\Sphere^{n^2-1}=\left\{  Z \in \Hermitian^n\colon \|  Z \|_2=1 \right\}$ be the (Frobenius norm) unit sphere and $\mathcal{B}_1 = \mathrm{conv} \left\{ \pm | x \rangle \! \langle  x| \colon  x \in \Sphere^{n-1} \right\}$ the trace-norm ball in $\Hermitian^n$.
  Define
  \[
    D := \Sphere^{d^2-1} \cap 3 \mathcal{B}_1.
    \label{eq:pl.D}
  \]
  Also, let $\mathcal{A}(Z) = \sum_{l=1}^m \tr ( A\ind{l}  Z ) \,  {e_l}$ be a measurement operator that obeys
  \begin{align}
      \frac{ \tau}{m} \| \mathcal{A}( Z) \|_{\ell_1} \geq& \norm{ Z}_2 \quad \forall  Z \in D \label{eq:pl.nsp}\\
      \| \frac{1}{\nu m}\sum_{l=1}^m  A\ind{l} -  \mathbb{I} \|_\infty \leq& \frac{1}{6}\label{eq:pl.approx_povm}
  \end{align}
  for some $\tau,\nu >0$.
  Then, the following relation holds for any $ Z \geq 0$ and any $\ketbra x$:
  \[
    \label{eq:pl.rec_guarantee}
    \Fnorm{Z - \ketbra{x}}
    \leq \frac{1}{m} \max \left\{ \tau, \frac{6}{\nu} \right\}  \Norm{\mathcal{A}\left( Z - \ketbra{x} \right)}_{\ell_1}.
  \]
\end{proposition}


\begin{proof}
In the proof we will frequently use the decomposition $ Z =  Z_1+ Z_c$ for $ Z$ with eigenvalue decomposition $ Z = \sum_{k=1}^n \lambda_k | z^{(k)} \rangle \! \langle  z^{(k)}|$.
Assuming $\lambda_1 \ge \ldots \ge \lambda_n$, $Z_1 = \lambda_1 | z^{(1)} \rangle \! \langle  z^{(1)}|$ is the leading rank-one component and $ Z_c =  Z- Z_1$ is the ``tail''.
Note that, in particular, $ Z =  Z_1$ if and only if $ Z$ has unit rank.
\Cref{eq:pl.rec_guarantee} is invariant under re-scaling, so we may w.l.o.g.\ assume $\|  Z-|{x} \rangle \! \langle {x}|\|_2=1$.
We treat the following two cases separately:
\begin{align}
  \mathrm{I.)} \quad& \| ( Z-|{x} \rangle \! \langle {x}|)_1 \|_1 \geq \frac{1}{2} \| ( Z-|{x} \rangle \! \langle {x}|)_c \|_1, \label{eq:pl.nsp_case1} \\
  \mathrm{II.)} \quad & \| ( Z-|{x} \rangle \! \langle {x}|)_1 \|_1 < \frac{1}{2} \| ( Z-|{x} \rangle \! \langle {x}|)_c \|_1. \label{eq:pl.nsp_case2}
\end{align}
Note that I.) implies
\begin{align}
  \|  Z-|{x} \rangle \! \langle {x}| \|_1 \leq &\| ( Z-|{x} \rangle \! \langle {x}|)_1 \|_1 + \| ( Z-|{x} \rangle \! \langle {x}|)_c \|_1 \leq 3 \| ( Z-|{x} \rangle \! \langle {x}|)_1 \|_1 \\
  = & 3 \| ( Z-|{x} \rangle \! \langle {x}|)_1 \|_2 \leq 3 \|  Z- |{x} \rangle \! \langle {x}| \|_2 = 3
\end{align}
which in turn implies that $ Z-| {x} \rangle \! \langle {x}|$ is contained in $3 \mathcal{B}_1$.
Thus, \eqref{eq:pl.nsp} is applicable and yields
\[
\|  Z - |{x} \rangle \! \langle {x}| \|_2 \leq  \frac{\tau}{m} \| \mathcal{A}( Z-|{x} \rangle \! \langle {x}|) \|_{\ell_1}
\]
which establishes \cref{eq:pl.rec_guarantee} for the case~\eqref{eq:pl.nsp_case1}.\\



For the second case, we use a consequence of von Neumann's trace inequality, see e.g. \cite[Theorem~7.4.9.1]{Horn_1994_Topics}:
Let $ A,  B$ be matrices with singular values $\sigma_k ( A),\sigma_k ( B)$ arranged in non-increasing order.
Then
\[
  \|  A -  B \|_1 \geq \sum_{k=1}^n | \sigma_k ( A) - \sigma_k ( B)|
\]
This relation implies
\begin{align}
  \|  Z \|_1 =& \| |{x} \rangle \! \langle {x}| - (|{x} \rangle \! \langle {x}|- Z) \|_1
  \geq \sum_{k=1}^n \left| \sigma_k (| x \rangle \! \langle  x|) - \sigma_k (| x \rangle \! |\langle  x|-  Z ) \right| \\
  \geq & \sigma_1 (| x \rangle \langle  x|) - \sigma_1 \left( | x \rangle \! \langle  x| -  Z \right)+ \sum_{k=2}^n \sigma_k \left( | x \rangle \! \langle  x| -  Z\right) \\
  =&  \| | x \rangle \! \langle  x| \|_1  - \| (| x \rangle \! \langle  x| -  Z)_1 \|_1 + \|(| x \rangle \! \langle  x| - Z)_c \|_1 \\
  >& \| | x \rangle \! \langle  x| \|_1 + \frac{1}{2} \| (| x \rangle \! \langle  x|- Z)_c \|_1,
\end{align}
where the last inequality follows from \eqref{eq:pl.nsp_case2}. Consequently,
\begin{align}
  \| | x \rangle \! \langle  x| -  Z \|_1
  =& \| (| x \rangle \! \langle  x| -  Z)_1 \|_1 + \| (| x \rangle \! \langle  x|- Z)_c \|_1
  \leq \frac{3}{2} \| (| x \rangle \! \langle  x|-  Z )_c \|_1 \nonumber \\
  < & 3 \left( \|  Z \|_1 - \| | x \rangle \! \langle  x| \|_1 \right). \label{eq:pl.nsp_aux2}
\end{align}
Now, positive semidefiniteness of both $ Z$ and $\ket{ x}\bra{ x}$ together with assumption~\eqref{eq:pl.approx_povm} implies
\begin{align}
  \|  Z \|_1 - \| |{x} \rangle \! \langle {x}| \|_1
  =& \tr ( Z-|{x} \rangle \! \langle {x}|) =  \tr \left( \mathbb{I} \left(  Z-| {x} \rangle \! \langle x|\right) \right) \\
  =&  \tr \left( \left( \mathbb{I} - \frac{1}{\nu m} \sum_{k=1}^m A\ind{l} \right)  Z-|{x} \rangle \! \langle {x}| \right) + \frac{1}{\nu m} \sum_{k=1}^m \tr \left( A_k ( Z-|{x} \rangle \! \langle {x}|) \right) \\
  \leq &  \left\|\mathbb{I}- \frac{1}{ \nu m} \sum_{k=1}^m A_k \right\|_\infty \|  Z-|{x} \rangle \! \langle {x}| \|_1 + \frac{1}{\nu m} \| \mathcal{A}(|{x} \rangle \! \langle {x}|- Z) \|_{\ell_1} \\
  \leq &  \frac{1}{6 } \|  Z-|{x} \rangle \! \langle {x}| \|_1 + \frac{1}{\nu m} \| \mathcal{A}(|{x} \rangle \! \langle {x}|- Z) \|_{\ell_1}.
\end{align}
Inserting this into \eqref{eq:pl.nsp_aux2} yields
\begin{align}
\| | x \rangle \! \langle  x| -  Z \|_1 < \frac{1}{2} \| |{x} \rangle \! \langle {x}|- Z \|_1 +  \frac{3}{\nu m} \| \mathcal{A}(|{x} \rangle \! \langle {x}|- Z) \|_{\ell_1}
\end{align}
which implies the claim for case II in \eqref{eq:pl.nsp_case2}.
\end{proof}


\begin{proposition} \label{prop:pl.nsp}
  Under the assumptions of \cref{thm:pl.phaselift_noisy}, the measurement operator
  \[
    \label{eq:pl.measurement_operator_rank1}
    \mathcal{A}(Z) = \sum_l \tr \left(\ketbra{\alpha\ind{l}}  Z\right) \, {e_l}
  \]
  obeys both condition~\eqref{eq:pl.nsp} and~\eqref{eq:pl.approx_povm} with probability at least $1- 3\mathrm{e}^{-\gamma m}$, provided that $C >1$ is sufficiently large.
\end{proposition}

We postpone the proof of this statement to \cref{sec:pl.proof_measurement_operator_is_good} and directly derive \cref{thm:pl.phaselift_noisy} -- the main theoretical achievement of this work -- from this statement.

\todo{It's gone!}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Proof of \cref{prop:pl.nsp}}
\label{sec:pl.proof_measurement_operator_is_good}

\begin{lemma}[Bound on the marginal tail function]
  Let $D$ be the set introduced in \cref{eq:pl.D} and let $ A = \ketbra\alpha$, where $\alpha$ satisfies \cref{eq:pl.sub_isotropy,eq:pl.subexponential}.
  Then, the marginal tail function~\eqref{eq:pl.marginal_tail_function} obeys
  \[
    Q_\xi (D,  A) \geq  C_Q \left( 1-  \frac{\xi^2}{C_\mathrm{SI}}\right)^2  \quad \forall 0 \leq \xi \leq \sqrt{C_\mathrm{SI}},
  \]
  where $C_Q>0$ is a sufficiently small constant.
\end{lemma}

\begin{proof}
Fix $ Z \in D$, then $\|  Z \|_2 =1$ by definition of $D$.
Note that sub-isotropy \eqref{eq:pl.sub_isotropy} and the Paley-Zygmund inequality imply for any $\xi \in [0,1]$
\begin{align}
  \Prob \left[ | \langle  a|  Z | a \rangle| \geq \xi \right]
  \geq & \Prob \left[ \langle  \alpha|  Z | \alpha \rangle^2 \geq \frac{\xi^2}{C_\mathrm{SI}} \mathbb{E} \left[ \langle  \alpha| Z| \alpha \rangle^2 \right] \right] \\
  \geq & \left(1-\frac{\xi^2}{C_\mathrm{SI}}\right)^2 \frac{\mathbb{E} \left[ \langle  \alpha | Z | \alpha \rangle^2 \right]^2}{\mathbb{E} \left[ \langle  \alpha|  Z | \alpha \rangle^4 \right]}.
\end{align}
Sub-isotropy ensures that the numerator is lower bounded by $C_\mathrm{SI}^2 \|  Z \|_2^4 = C_\mathrm{SI}^2$.
In order to derive an upper bound on the denominator, we use the constraint $\|  Z \|_1 \leq 3$ for any $ Z \in D$ together with the subgaussian tail behavior \eqref{eq:pl.subexponential} of $\alpha$.
Insert an eigenvalue decomposition $ Z = \sum_{i=1}^n \lambda_i | z^{(i)} \rangle \! \langle  z^{(i)}|$ (with $\lambda_i \in \mathbb{R}$ and $ z^{(i)} \in \Sphere^{n-1}$) and note
\begin{align}
  \mathbb{E} \left[ \langle  \alpha|  Z | \alpha \rangle^4 \right]
  \leq & \sum_{i_1,i_2,i_3,i_4=1}^n | \lambda_{i_1} \lambda_{i_2} \lambda_{i_3} \lambda_{i_4} | \mathbb{E} \left[ \prod_{k=1}^4 | \langle  \alpha,  z^{(i_k)} \rangle|^2 \right]. \label{eq:pl.Q_aux1}
\end{align}
Now fix $ z^{(i_1)},\ldots, z^{(i_4)}$ and use the inequality of arthimetic and geometric means as well as the fundamental relation between $\ell_p$-norms ($\|  v \|_{\ell_1} \leq k^{1-\frac{1}{k}} \|  v \|_{\ell_k}$ for $v \in \mathbb{R}^k$) to conclude
\begin{align}
  \mathbb{E} \left[ \prod_{k=1}^4 | \langle  \alpha, z^{(i_k)}\rangle |^2 \right]
  \leq \frac{1}{4} \sum_{k=1}^4 \mathbb{E} \left[ | \langle  \alpha,  z^{(i_k)} \rangle|^8 \right]
  \leq C_\mathrm{SG} 4!,
\end{align}
where the last inequality follows from condition \eqref{eq:pl.subexponential}.
Consequently,
\begin{align}
  \mathbb{E} \left[ \langle  \alpha|  Z |  \alpha\rangle^4 \right]
  \leq C_\mathrm{SG} 4! \sum_{i_1,i_2,i_3,i_4} | \lambda_{i_1} \lambda_{i_2} \lambda_{i_3} \lambda_{i_4} |
  = 24 C_\mathrm{SG} \|  Z \|_1^4 \leq 24 \times 3^4 C_\mathrm{SG},
\end{align}
because $ Z \in D$ implies $\|  Z \|_1 \leq 3$.
In summary,
\begin{align}
  \Prob \left[ | \langle  \alpha|  Z | \alpha \rangle| \geq \xi \right]
  \geq \left(1-\frac{\xi^2}{C_\mathrm{SI}}\right)^2 \frac{\mathbb{E} \left[ \langle  \alpha|  Z | a \rangle^2 \right]^2}{\mathbb{E} \left[ \langle  \alpha|  Z | \alpha \rangle^4 \right]}
  \geq \left(1-\frac{\xi^2}{C_\mathrm{SI}}\right)^2 \frac{C_\mathrm{SI}^2}{1944C_\mathrm{SG}}
\end{align}
and the bound on $Q_\xi (D, A)$ with $C_Q = \frac{C_\mathrm{SI}^2}{1944 C_\mathrm{SG}}$ follows from the fact that this lower bound holds for any $ Z \in D$.
\end{proof}



\begin{lemma}[Bound on the mean empirical width]
  Let $D$ be the set introduced in \cref{eq:pl.D} and let $ H = \frac{1}{\sqrt{m}} \sum_{l=1}^m \eta_l \ketbra{\alpha\ind{l}}$, where each $\alpha\ind{l}$ is subexponential in the sense of \eqref{eq:pl.subexponential} and $m \geq \frac{2 \ln (3)}{C_\mathrm{SG}} n$.
  Then there exists a constant $C_\mathrm{W} >0$ such that
  \[
    W_m (D, A) \leq C_\mathrm{W} \sqrt{n}.
  \]
\end{lemma}

\begin{proof}
  Note that by construction $D \subset 3 \mathcal{B}_1$, and consequently,
  \begin{align}
    W_m (D,  A) = 2 \mathbb{E} \left[ \sup_{ Z \in D} \tr ( Z  H) \right] \leq 6 \mathbb{E} \left[ \sup_{ Z \in \mathcal{B}_1} \tr ( Z  H) \right] = 6 \mathbb{E} \left[ \|  H \|_\infty  \right], \label{eq:pl.Wm_hoelder}
  \end{align}
  where the last equality follows from the duality of trace and operator norm.
  Now note that $\tilde{ H} = \sqrt{m}  H$ is of the form~\eqref{eq:pl.Htilde}, where each $\alpha\ind{l}$ is an independent Rademacher random variable.
  \Cref{thm:bernstein} thus implies
  \begin{align}
    \Prob \left[\|  H \|_\infty \geq t \right]
    \leq
    \begin{cases}
     2 \times 9^n \exp \left( - \frac{t^2}{8 C_\mathrm{SG}} \right) & t \leq 2C_\mathrm{SG} \sqrt{m}, \\
    2 \times 9^n \exp \left( - \frac{\sqrt{m}}{2} \left( t - C_\mathrm{SG} \sqrt{m} \right) \right) & t \geq 2 C_\mathrm{SG} \sqrt{m}
    \end{cases}
    \label{eq:pl.Wm_tails}
  \end{align}
  and we can bound $\mathbb{E} \left[ \|  H \|_\infty \right]$ by using the absolute moment formula,
  %$
  %\mathbb{E} \left[ \| H \|_\infty \right] = \int_0^\infty \Prob \left[ \| H \|_\infty \geq t \right] \mathrm{d}t,
  %$
  see e.g.\ \cite[Propostion~7.1]{Foucart_2013_Mathematical}, and bounding the effect of the tails via \eqref{eq:pl.Wm_tails}.
  To this end, we split the real line into three intervals $[0, c \sqrt{n}], [c\sqrt{n}, 2 C_\mathrm{SG} \sqrt{m}], [2 C_\mathrm{SG} \sqrt{m},\infty[$, where $c$ is a constant that we fix later:
  \begin{align}
    \mathbb{E} \left[ \| H\|_\infty \right]
    &=& \int_0^\infty \Prob \left[ \| H\|_\infty \geq t \right] \mathrm{d}t \\
    &\leq& \int_0^{c \sqrt{n}} 1 \mathrm{d}t + 2 \times 9^n \left( \int_{c \sqrt{n}}^{2 C_\mathrm{SG} \sqrt{m}} 2 \exp \left( - \frac{t^2}{8 C_\mathrm{SG}} \right) \mathrm{d}t
     +  \mathrm{e}^{\frac{m C_\mathrm{SG}}{2}} \int_{2 C_\mathrm{SG} \sqrt{m}}^\infty \exp\left( - \frac{\sqrt{m}t}{2}  \right) \mathrm{d} t \right)\\
    &\leq & c \sqrt{n} + 2 \times 9^n \left( \int_{c \sqrt{n}}^{2 C_\mathrm{SG} \sqrt{m}}  \exp \left( - \frac{t^2}{8 C_\mathrm{SG}} \right) \mathrm{d}t + \frac{2}{\sqrt{m}} \mathrm{e}^{-\frac{C_\mathrm{SG} m}{2}}\right).
  \end{align}
  For the remaining Gauss integral, we use $\frac{t}{c \sqrt{n}} \geq 1\; \forall t \geq c\sqrt{n}$ to conclude
  \begin{align}
    \int_{c \sqrt{n}}^{2 C_\mathrm{SG} \sqrt{m}}  \exp \left( - \frac{t^2}{8 C_\mathrm{SG}} \right) \mathrm{d}t
    %\leq & \int_{C \sqrt{n}}^{4 \mathrm{e}^2 \sqrt{m}} \frac{t}{C \sqrt{n}}  \exp \left( - \frac{t^2}{32 \mathrm{e}^2} \right) \mathrm{d} t
    \leq  \int_{c \sqrt{n}}^\infty \frac{t}{c \sqrt{n}}  \exp \left( - \frac{t^2}{8 C_\mathrm{SG}} \right) \mathrm{d} t
    %=& - \frac{32 \mathrm{e}^2}{C\sqrt{n}} \exp \left( - \frac{t^2}{32 \mathrm{e}^2}\right) |_{t=C \sqrt{n}}^{t=\infty}
    = \frac{8 C_\mathrm{SG}}{c \sqrt{n}} \exp \left( - \frac{c^2 n}{8 C_\mathrm{SG}} \right).
  \end{align}
  Now, fixing $c = 4 \sqrt{\ln (3)C_\mathrm{SG}}$ assures $\exp \left( -\frac{c^2 n}{8 C_\mathrm{SG}}\right) = 9^{-n}$ and consequently
  \begin{align}
    \mathbb{E} \left[ \|  H \|_\infty \right]
    \leq & 4  \sqrt{ \ln (3) C_\mathrm{SG} n} + \frac{4 \sqrt{C_\mathrm{SG}}}{\sqrt{ \ln (3) n}} + \frac{4}{\sqrt{m}} \mathrm{e}^{2 \ln (3) n - C_\mathrm{SG} m} \\
    %\leq &8 \mathrm{e} \sqrt{ \ln (3) n} + \frac{8 \mathrm{e}}{\sqrt{ \ln (3) n}} + \frac{8 \mathrm{e}}{\sqrt{4 \ln (3) n}} \\
    \leq & 4\sqrt{C_\mathrm{SG}} \left( \sqrt{ \ln (3) n} + \frac{2}{\sqrt{ \ln (3) n}} \right) \leq 12 \sqrt{ \ln (3) C_\mathrm{SG} n}.
  \end{align}
  where the second inequality follows from $m \geq \frac{2 \ln (3)}{C_\mathrm{SG}} n$. Inserting this bound into \eqref{eq:pl.Wm_hoelder} yields the claim with $C_\mathrm{W} = 72 \sqrt{ \ln (3) C_\mathrm{SG}}$.
\end{proof}

Now we are ready to apply Mendelson's small ball method \eqref{eq:pl.mendelson}.
For $D$ defined in \eqref{eq:pl.D} and measurements $ A_l = \ketbra{\alpha\ind{l}}$ with $\alpha_l$ obeying \cref{eq:pl.sub_isotropy,eq:pl.subexponential}, the bounds from the previous Lemmas imply
\begin{align}
  \frac{1}{\sqrt{m}}\inf_{ Z \in D} \|\mathcal{A}( Z) \|_{\ell_1} \geq \xi \sqrt{m} C_Q \left( 1- \frac{4 \xi^2}{C_\mathrm{SI}} \right)^2 - 2 C_\mathrm{W} \sqrt{n} - \xi t \quad \forall \xi \in (0, 1/\sqrt{C_\mathrm{SI}}), \forall t \geq 0
\end{align}
with probability at least $1- \mathrm{e}^{-2t^2}$. We choose $\xi = \sqrt{C_\mathrm{SI}}/4$ and $t = \gamma_1 \sqrt{m}$, where $\gamma_1 = \frac{9 C_Q}{32}$ and obtain with probability at least $1-\exp \left( -2 \gamma_1 m \right)$:
\begin{align}
  \frac{1}{\sqrt{m}}\inf_{ Z \in D} \|\mathcal{A}( Z) \|_{\ell_1} \geq & \frac{9 C_Q\sqrt{C_\mathrm{SI}}}{64} \sqrt{m} -  C_\mathrm{W}\sqrt{n} - \frac{\sqrt{C_\mathrm{SI}}}{4} \frac{9 C_Q}{32} \sqrt{m} \\
  = & C_\mathrm{W} \left( \frac{9 C_Q \sqrt{C_\mathrm{SI}}}{128 C_\mathrm{W}} \sqrt{m} - \sqrt{n} \right).
\end{align}
Setting $m = C n$ with $C = \left( \frac{256 C_\mathrm{W}}{9 C_Q \sqrt{C_l}} \right)^2$ implies
\[
  \frac{1}{\sqrt{m}} \inf_{ Z \in D} \| \mathcal{A}( Z) \|_{\ell_1} \geq 2 C_\mathrm{W} \sqrt{n} = \frac{2 C_\mathrm{W}}{\sqrt{C}} \sqrt{m}
\]
with probability at least $1- \mathrm{e}^{-2 \gamma_1 m}$.
For $\tau = \frac{ 2 C_\mathrm{W}}{\sqrt{C}}$, the first claim in \cref{prop:pl.nsp} follows from rearranging this expression and using $\|  Z \|_2=1$ for all $ Z \in D$.\\


Let us now move on to establishing the second statement \eqref{eq:pl.approx_povm}:
Isotropy \eqref{eq:pl.tight_frame} implies
\begin{align}
  \frac{1}{ C_\mathrm{I} m} \sum_{l=1}^m \ketbra{\alpha\ind{l}} - \mathbb{I}
  = \frac{1}{C_\mathrm{SG} m} \sum_{l=1}^m \left( \ketbra{\alpha\ind{l}} - \mathbb{E} \left[ \ketbra{\alpha\ind{l}} \right] \right)
\end{align}
and each $\alpha\ind{l}$ has subgaussian tails by assumption \eqref{eq:pl.subexponential}.
Thus, \cref{thm:bernstein} is applicable and setting $t= \min \left\{\frac{1}{6},2 C_\mathrm{SG} \right\}$ yields
\begin{align}
  \Prob \left[ \left\| \frac{1}{C_\mathrm{I} m} \sum_{l=1}^m \ketbra{\alpha\ind{l}} -  \mathbb{I} \right\|_\infty \geq \frac{1}{6} \right]
  & \leq 2 \exp \left( 2 \ln (3) n - \frac{C_\mathrm{I} m \min\left\{ 1/6, 2 C_\mathrm{SG} \right\}}{8 C_\mathrm{SG}} \right) \\
  & \leq 2 \exp \left( - \gamma_2 m \right),
\end{align}
where the second inequality follows from $m \geq C n$, provided that $C$ is sufficiently large. Finally, we use the union bound  for the overall probability of failure and set $\gamma := \min \left\{ 2 \gamma_1,\gamma_2 \right\}$.



\section{Proof of \cref{prop:gauss+recr_requirements}}
\label{sec:pl.gauss+recr_requirements}

We now proof the crucial properties \eqref{eq:pl.tight_frame}--\eqref{eq:pl.subexponential} for the different measurement ensembles from \cref{prop:gauss+recr_requirements}.

\subsection{The Gaussian sampling scheme}


Let $\alpha \in \mathbb{C}^n$ be a standard (complex) Gaussian vector and fix any $ z \in \mathbb{C}^n$.
Then, the random variable $\langle \alpha, z \rangle$ is an instance of a standard (complex normal) random variable $a = \tfrac{\|  z \|_{\ell_2}}{\sqrt{2}} \left(a_R + i a_I\right)$ with $a_R, a_I \sim \mathcal{N}(0,1)$.
In turn, $|a|^2 = \frac{\|  z \|_{\ell_2}^2}{2} (a_R^2 + a_I^2)$ is a rescaled version of a $\chi^2$-distributed random variable with two degrees of freedom.
The moments of such a random variable are well-known and we obtain
\[
  \mathbb{E} (| \langle \alpha, z \rangle|^{2N})= \left( \frac{ \|  z \|_{\ell_2}}{\sqrt{2}}\right)^N \times 2^N N! = \|  z \|_{\ell_2}^N N! \; .\label{eq:pl.moments_gauss}
\]
From this, we can readily infer $C_\mathrm{SG} = 1$, and the special case $N=1$  yields $C_\mathrm{I}=1$.

For the remaining expression, use an eigenvalue decomposition $ Z = \sum_{k=1}^d \zeta_k | z^{(k)} \rangle \langle  z^{(k)}|$ (with normalized eigenvectors $ z^{(k)}\in \mathbb{C}^n$) and note that the random variables $|\langle  a, z^{(1)} \rangle|,\ldots, | \langle  a, z^{(n)} \rangle|$ are independently distributed and obey \cref{eq:pl.moments_gauss}.
Consequently:
\begin{align}
  \mathbb{E} \left[ \tr \left(  A  Z \right)^2 \right]
  =& \mathbb{E} \left[ \left( \sum_{k=1}^d \zeta_k | \langle \alpha, z^{(k)} \rangle|^2 \right)^2 \right] \\
  =& \sum_{k \neq l} \zeta_k \zeta_l \mathbb{E} \left[ |\langle \alpha, z^{(k)} \rangle|^2 \right] \mathbb{E} \left[ | \langle  a, z^{(l)} \rangle|^2 \right]
  + \sum_{k=1}^d \zeta_k^2 \mathbb{E} \left[ | \langle  a,  z^{(k)} \rangle|^4 \right] \\
  =& \sum_{k \neq l} \zeta_k \zeta_l \| z^{(k)} \|_{\ell_2}^2 \|  z^{(l)} \|_{\ell_2}^2 + 2 \sum_{k=1}^d \zeta_k^2 \|  z^{(k)} \|_{\ell_2}^4
  = \sum_{k,l=1}^d \zeta_k \zeta_l + 2\sum_{k=1}^d \zeta_k^2 \\
  =& \tr ( Z)^2 + \tr ( Z^2)
  \geq \|  Z \|_2^2,
\end{align}
which implies $C_\mathrm{SI} = 1$.

\subsection{The uniform sampling scheme}

Here, $\alpha$ is chosen uniformly from the complex sphere with radius $\sqrt{n}$.
This in turn implies that the distribution of $\alpha \in \mathbb{C}^n$ is invariant under arbitrary unitary transformations.
Techniques from representation theory -- more precisely: Schur's Lemma -- then imply
\[
  \label{eq:pl.from_schur}
  \mathbb{E} \left[ (|\alpha \rangle \! \langle \alpha| )^{\otimes N} \right] =
  %\mathbb{E} \left[ U^{\otimes N} (|a_0 \rangle \! \langle a_0|)^{\otimes N} (U^\dagger)^{\otimes N} \right] = \binom{n+N-1}{n}^{-1} \| a_0\|_{\ell_2}^N P_{\vee^N} =
  n^N \binom{n+N-1}{N}^{-1}  P_{\vee^N},
\]
see e.g.\ \cite[Lemma~1]{Scott_2006_Tight}.
Here, $ P_{\vee^N}$, denotes the projector onto the totally symmetric subspace $\bigvee\!^N \subset \left( \mathbb{C}^n \right)^{\otimes N}$.
Note that $\left(| z \rangle \! \langle  z| \right)^{\otimes N} \in \bigvee\!^N$ and, moreover $2 \mathrm{tr} \left(  P_{\vee^2}  Z^2 \right)= \|  Z \|_2^2 + \mathrm{tr} ( Z)^2$ for any matrix $ Z$, see e.g.\ \cite[Lemma~17]{Kueng_2016_Low}.
Consequently,
\begin{align}
  \mathbb{E} \left[ | \langle\alpha, z \rangle|^2 \right]
  =& \mathrm{tr} \left( | z \rangle \! \langle  z| \, \mathbb{E} \left[ |\alpha \rangle \! \langle\alpha| \right] \right)
  = \mathrm{tr} \left( | z \rangle \! \langle  z| \mathbb{I} \right) = \|  z \|_{\ell_2}^2, \\
  \mathbb{E} \left[
  \langle\alpha| Z |\alpha \rangle^2 \right]
  =& \tr \left( \mathbb{E} \left[ (|\alpha \rangle \! \langle\alpha|)^{\otimes 2} \right]  Z^{\otimes 2} \right)
  = \frac{n}{n+1} \left( \|  Z \|_2^2 + \mathrm{tr}( Z)^2 \right) \geq \frac{n}{n+1} \|  Z \|_2^2, \\
  \mathbb{E} \left[ | \langle\alpha,  z \rangle |^{2N} \right]
  =& \mathrm{tr} \left(\mathbb{E} \left[ (|\alpha \rangle \! \langle\alpha|)^{\otimes N} \right]  (| z\rangle \! \langle  z|)^{\otimes N}  \right)
  = n^N \binom{n+N-1}{N}^{-1} \|  z \|_{\ell_2}^{2N} \\
  =& N! \frac{n^N (n-1)!}{(n+N-1)!} \leq N!,
\end{align}
which implies $C_\mathrm{I}=1$, $C_\mathrm{SI} = \frac{n}{n+1}$ and $C_\mathrm{SG}=1$.


\subsection{The RECR sampling scheme}

\begin{lemma}[The RECR ensemble is isotropic on $\mathbb{C}^n$]
Suppose that $\alpha$ is chosen from a RECR ensemble with erasure probability $1-p$. Then
\begin{align}
  \mathbb{E} \left[ | \langle  \alpha, z \rangle|^2 \right] = p \|  z \|_{\ell_2}^2
  \quad \forall  z \in \mathbb{C}^n.
\end{align}
\end{lemma}

\begin{proof}
Let $\alpha_k = \langle  e_k, \alpha\rangle$, where $ e_1,\ldots, e_n$ is the orthonormal basis with respect to which the RECR vector is defined.
Theses components obey $\mathbb{E}\left[ \alpha_k \right] = \mathbb{E} \left[ \cc{\alpha}_k \right] = 0$, as well as $\mathbb{E} \left[ |\alpha_k|^2 \right] = p$.
For any $ z \in \mathbb{C}^n$ we then have
\begin{align}
  \mathbb{E} \left[| \langle  \alpha,  z\rangle |^2 \right]
  =& \sum_{i,j=1}^n \mathbb{E} \left[ \cc{\alpha}_i \alpha_j \right] \langle  e_i |  z \rangle \langle  z |  e_j \rangle = p \sum_{i=1}^n | \langle  e_i,  z \rangle|^2 = p \|  z \|_{\ell_2}^2.
\end{align}
\end{proof}

\begin{lemma}[The RECR ensemble is sub-isotropic on $\Hermitian^n$]
  \label{lem:recr_subisotropic}
  Suppose that $\alpha$ is chosen from a RECR ensemble with erasure probability $1-p$. Then
  \[
  \mathbb{E} \left[ \langle  \alpha|  Z | \alpha \rangle^2 \right] \geq p \min \left\{ p, 1-p \right\} \|  Z \|_2^2 \quad \forall  Z \in \Hermitian^n
  \]
\end{lemma}

\begin{proof}
Fix $ Z \in \Hermitian^n$ and compute
\begin{align}
  \mathbb{E} \left[ \langle \alpha |  Z | \alpha \rangle^2 \right]
  =& \sum_{i,j,k,l} \mathbb{E} \left[ \bar{\alpha}_i \alpha_j \cc{\alpha^\prime_k} \alpha^\prime_l \right] \langle  e_i| Z|  e_j \rangle \langle  e_k | Z|  e_l \rangle \\
  =& \sum_{i} \mathbb{E} \left[ | \alpha_i |^4 \right] \langle  e_i| Z| e_i \rangle^2 + \sum_{i \neq k} \mathbb{E} \left[ | \alpha_i |^2 | \alpha_k|^2 \right] \left( \langle  e_i| Z| e_i \rangle \langle  e_k| Z| e_k \rangle + \langle  e_i| Z| e_k \rangle \langle  e_k|  Z| e_i \rangle \right) \\
  =& p \sum_{i=1}^n \langle  e_i| Z| e_i \rangle^2 + p^2 \sum_{i \neq k} \left( \langle  e_i| Z| e_i \rangle \langle  e_k| Z| e_k \rangle + \langle  e_i| Z| e_k \rangle \langle  e_k | Z|  e_i\rangle \right) \\
  =& p^2 \sum_{i,k=1}^n \left( \langle  e_i| Z| e_i \rangle \langle  e_k| Z| e_k \rangle + \langle  e_i| Z| e_k \rangle \langle  e_k | Z|  e_i\rangle \right) + p(1-2 p) \sum_{i=1}^n \langle  e_i| Z| e_i \rangle^2 \\
  =& p^2 \left( \tr ( Z)^2 + \| Z\|_2^2 \right) + p (1-2 p) \sum_{i=1}^n \langle  e_i|  Z |  e_i \rangle^2 \\
  \geq& p^2 \| Z\|_2^2 + p(1-p) \sum_{i=1}^n \langle  e_i | Z| e_i \rangle^2
\end{align}
Finally, we make a case distinction:
\begin{itemize}
\item[$p \leq 1/2$]: This implies $p(1-2p) \geq 0$ and consequently
\begin{align}
  \mathbb{E} \left[ \langle \alpha | Z| \alpha \rangle^2 \right] \geq p^2 \|  Z \|_2^2.
\end{align}
\item[$p \geq 1/2$]: Use $\sum_{i=1}^n \langle i| X|i \rangle^2 \leq \| X \|_2^2$ to conclude
\begin{align}
  \mathbb{E} \left[ \langle \alpha |  Z | \alpha \rangle^2 \right]
\geq ( p^2 - p|1-2p|) \| Z\|_2^2 = p(1-p) \|  Z \|_2^2.
\end{align}
\end{itemize}
\end{proof}

\begin{lemma}[Subgaussian tails of the RECR distribution]
Suppose that $\alpha$ is a vector from the RECR ensemble. Then
\begin{align}
\mathbb{E} \left[ | \langle \alpha,  z \rangle|^{2N} \right] \leq \mathrm{e}^{\frac{3}{2}} N! \quad \forall  z \in \Sphere^{n-1}.
\end{align}
\end{lemma}

\begin{proof}
Fix $ z \in \mathbb{C}^n$ with $\|  z \|_{\ell_2}=1$ and note that $|\alpha_k| \leq 1$ together with the independence of $\alpha_k,\alpha_l$ for $k \neq l$ implies
\begin{align}
  \mathbb{E} \left[ \exp \left( | \langle \alpha,  z \rangle|^2 \right) \right]
  =& \mathbb{E} \left[ \prod_{k=1}^n \exp \left( | \alpha_k|^2 |z_k|^2 \right) \prod_{k \neq l} \exp \left( \cc{\alpha}_k \alpha_l \cc{z}_k z_l \right) \right] \nonumber \\
  \leq& \exp \left( \|  z \|_{\ell_2}^2 \right) \prod_{k \neq l} \mathbb{E} \left[  \exp \left( \cc{\alpha}_k \alpha_l \cc{z}_k z_l \right)  \right]. \label{eq:pl.moment_aux1}
\end{align}
Now note that for $k \neq l$, $\cc{\alpha}_k \alpha_l$ is again a RECR random variable $\tilde{\alpha}_{k,l}$, but with erasure probability $1-p^2$.
Moreover, every RECR random variable $\alpha$ can be decomposed into the product of two independent random variables: $ \alpha= \eta \omega$, where $\eta$ is a Rademacher random variable and $\omega \in \left\{0, 1,i \right\}$ obeys $| \omega | \leq 1$.
Consequently
\begin{align}
  \mathbb{E} \left[ \exp \left( \bar{\alpha}_k \alpha_l \bar{z}_k z_l \right) \right]
  =& \mathbb{E} \left[ \exp \left( \tilde{\alpha}_{k,l} \bar{z}_k z_l \right) \right]
  = \mathbb{E}_{\omega} \left[ \mathbb{E}_\eta \left[ \eta \omega \bar{z}_k  z_l \right] \right]
  = \mathbb{E}_{\omega} \left[ \cosh \left( \omega \bar{z}_k z_l \right) \right] \\
  \leq & \mathbb{E}_\omega \left[ \exp \left( |\omega \bar{z}_k z_l|^2/2 \right) \right]
  \leq  \exp \left( \frac{|z_k|^2 |z_l|^2}{2} \right),
\end{align}
where we have used the standard estimate $\cosh (x) \leq \exp \left( |x|^2/2 \right)$ $\forall x \in \mathbb{C}$, as well as $| \omega| \leq 1$. Inserting this bound into \eqref{eq:pl.moment_aux1} yields
\begin{align}
  \mathbb{E} \left[ \exp \left( | \langle  \alpha,  z \rangle|^2 \right) \right]
  \leq \exp \left( \|  z \|_2^2 \right) \prod_{k \neq l} \exp \left( \frac{|z_k|^2 |z_l|^2}{2} \right)
  \leq \exp \left( \|  z \|_2^2 + \frac{1}{2}\|  z \|_{\ell_2}^4 \right) = \mathrm{e}^{\frac{3}{2}},
\end{align}
because $\|  z \|_{\ell_2}=1$.
Markov's inequality shows that this exponential bound implies a subexponential tail bound for the random variable $| \langle  \alpha, z \rangle|^2$:
\begin{align}
  \Prob \left[ | \langle \alpha, z \rangle|^2 \geq t \right]
  =& \Prob \left[ \exp \left( | \langle  \alpha, z \rangle|^2 \right) \geq \exp \left( t \right) \right]
  \leq \frac{ \mathbb{E} \left[ \exp \left( | \langle \alpha,  z \rangle|^2 \right) \right]}{\exp (t)} \leq \mathrm{e}^{\frac{3}{2}-t}.
\end{align}
This in turn implies the following bound on the moments:
\begin{align}
  \mathbb{E} \left[ | \langle  \alpha, z \rangle|^{2N} \right]
  =  N \int_0^\infty \Prob\left[ | \langle  \alpha, z \rangle|^2\geq t \right] t^{N-1} \mathrm{d}t \leq N \mathrm{e}^{\frac{3}{2}} \int_0^\infty \mathrm{e}^{-t} t^{N-1} \mathrm{d}t
  = \mathrm{e}^{\frac{3}{2}} N!,
\end{align}
where we have used a well-known integration formula for moments, see e.g.\ \cite[Prop.~7.1]{Foucart_2013_Mathematical}, as well as integration by parts.
\end{proof}


\subsection{The normalized RECR scheme}
\label{sub:pl.normalized_recr}

