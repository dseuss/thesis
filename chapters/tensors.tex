 % -*- root: ../thesis.tex -*-
\chapter{Tensors}
\label{chap:tensors}

As we already mentioned in \cref{chap:phaselift}, low-rank matrix recovery is a natural progression from compressed sensing, which deals with sparse vectors, to matrices, which are sparse in their eigenbasis.
\todo{More specific reference.}
In this chapter, we deal with the next logical step in this progression, namely low-rank tensor recovery.
Besides practical applications in quantum physics, machine learning, and many more, it is also a fascinating subject from the theoretical point of view:
Whereas compressive sensing and low-rank matrix recovery provide a polynomial (linear) advantage in the sample complexity compared to \quotes{naive} approaches, the ultimate goal of low-rank tensor recovery is to provide protocols with an exponentially reduced sample complexity.
\todo{Exponential with respect to what?}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section{Matrix Product States}
\label{sec:tensors.mps}

